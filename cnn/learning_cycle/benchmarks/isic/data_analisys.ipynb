{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('results/all_metrics.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df.groupby(['model_name'], as_index=False)\n",
    "# count = 0\n",
    "\n",
    "# df_aux = pd.DataFrame()\n",
    "\n",
    "# for model_name, group in df2:\n",
    "#     df_aux = df_aux.append(group.sort_values(by='loss', ascending=True).head(3), ignore_index=True)\n",
    "#     df_aux = df_aux.append(group.sort_values(by='accuracy', ascending=False).head(3), ignore_index=True)\n",
    "#     df_aux = df_aux.append(group.sort_values(by='balanced_accuracy', ascending=False).head(3), ignore_index=True)\n",
    "#     df_aux = df_aux.append(group.sort_values(by='auc', ascending=False).head(3), ignore_index=True)\n",
    "#     count += 1\n",
    "\n",
    "# print(len(df_aux))\n",
    "# df_aux = df_aux.drop_duplicates()\n",
    "# print(len(df_aux))\n",
    "\n",
    "df_aux = df[['model_name', 'partition', 'optimizer', 'batch_size', 'lr_init', 'loss', 'accuracy', 'balanced_accuracy', 'auc']]\n",
    "df_aux = df_aux[(df_aux['partition'] == 'test') | (df_aux['partition'] == 'test-last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.172527</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.695181</td>\n",
       "      <td>0.860816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.288994</td>\n",
       "      <td>0.728333</td>\n",
       "      <td>0.694591</td>\n",
       "      <td>0.853451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.171221</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.691703</td>\n",
       "      <td>0.864152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.266605</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.689457</td>\n",
       "      <td>0.858832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.184604</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.681066</td>\n",
       "      <td>0.850333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.631030</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.343742</td>\n",
       "      <td>0.523124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.632715</td>\n",
       "      <td>0.438333</td>\n",
       "      <td>0.342789</td>\n",
       "      <td>0.504730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.668658</td>\n",
       "      <td>0.421667</td>\n",
       "      <td>0.338018</td>\n",
       "      <td>0.500644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.688087</td>\n",
       "      <td>0.488333</td>\n",
       "      <td>0.322799</td>\n",
       "      <td>0.504213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.738044</td>\n",
       "      <td>0.456667</td>\n",
       "      <td>0.313249</td>\n",
       "      <td>0.501595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name  partition optimizer  batch_size  lr_init      loss  \\\n",
       "131  efficientnet_b0       test     AdamW          32   0.0010  1.172527   \n",
       "560  efficientnet_b0       test     AdamW          16   0.0010  1.288994   \n",
       "132  efficientnet_b0  test-last     AdamW          32   0.0010  1.171221   \n",
       "617  efficientnet_b0  test-last      Adam          32   0.0010  1.266605   \n",
       "613  efficientnet_b0       test      Adam          16   0.0010  1.184604   \n",
       "..               ...        ...       ...         ...      ...       ...   \n",
       "695  efficientnet_b0  test-last  Adadelta          16   0.0001  2.631030   \n",
       "701  efficientnet_b0  test-last  Adadelta          64   0.0001  2.632715   \n",
       "700  efficientnet_b0       test  Adadelta          64   0.0001  2.668658   \n",
       "697  efficientnet_b0       test  Adadelta          32   0.0001  2.688087   \n",
       "698  efficientnet_b0  test-last  Adadelta          32   0.0001  2.738044   \n",
       "\n",
       "     accuracy  balanced_accuracy       auc  \n",
       "131  0.726667           0.695181  0.860816  \n",
       "560  0.728333           0.694591  0.853451  \n",
       "132  0.736667           0.691703  0.864152  \n",
       "617  0.725000           0.689457  0.858832  \n",
       "613  0.695000           0.681066  0.850333  \n",
       "..        ...                ...       ...  \n",
       "695  0.413333           0.343742  0.523124  \n",
       "701  0.438333           0.342789  0.504730  \n",
       "700  0.421667           0.338018  0.500644  \n",
       "697  0.488333           0.322799  0.504213  \n",
       "698  0.456667           0.313249  0.501595  \n",
       "\n",
       "[71 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'efficientnet_b0'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# AdamW 32 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.168047</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.691362</td>\n",
       "      <td>0.846854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.015031</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.685350</td>\n",
       "      <td>0.854534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.207058</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.685131</td>\n",
       "      <td>0.850821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.967837</td>\n",
       "      <td>0.723333</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.844506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.146235</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.674887</td>\n",
       "      <td>0.850072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.998059</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>0.669572</td>\n",
       "      <td>0.846367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.281885</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.665077</td>\n",
       "      <td>0.849811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.392630</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.641452</td>\n",
       "      <td>0.820993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.963142</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>0.638840</td>\n",
       "      <td>0.828396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.953854</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.638109</td>\n",
       "      <td>0.823161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.338723</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.637320</td>\n",
       "      <td>0.793081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.060995</td>\n",
       "      <td>0.698333</td>\n",
       "      <td>0.635889</td>\n",
       "      <td>0.826325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.419632</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.635767</td>\n",
       "      <td>0.816499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.224814</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.635397</td>\n",
       "      <td>0.819998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.143181</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.630010</td>\n",
       "      <td>0.809808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.214060</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.627659</td>\n",
       "      <td>0.819401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.203934</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.627063</td>\n",
       "      <td>0.821680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.441309</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.627007</td>\n",
       "      <td>0.787762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.019405</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.625626</td>\n",
       "      <td>0.823367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.308116</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.622701</td>\n",
       "      <td>0.807495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.622203</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.621578</td>\n",
       "      <td>0.832496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.491638</td>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.613695</td>\n",
       "      <td>0.780426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.132541</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.612029</td>\n",
       "      <td>0.811827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.412577</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.610994</td>\n",
       "      <td>0.790098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.920230</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.610870</td>\n",
       "      <td>0.805517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.134733</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.610676</td>\n",
       "      <td>0.820274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.458906</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.609039</td>\n",
       "      <td>0.776103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.385814</td>\n",
       "      <td>0.636667</td>\n",
       "      <td>0.592521</td>\n",
       "      <td>0.768265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.581210</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.589043</td>\n",
       "      <td>0.788684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.570435</td>\n",
       "      <td>0.651667</td>\n",
       "      <td>0.585877</td>\n",
       "      <td>0.788642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.899000</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.543248</td>\n",
       "      <td>0.711129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.979433</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.536833</td>\n",
       "      <td>0.705909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.112760</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.514882</td>\n",
       "      <td>0.684409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2.413231</td>\n",
       "      <td>0.488333</td>\n",
       "      <td>0.511613</td>\n",
       "      <td>0.676766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.057528</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.504845</td>\n",
       "      <td>0.676767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2.544599</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.477238</td>\n",
       "      <td>0.664129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2.071319</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.429984</td>\n",
       "      <td>0.612907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2.117463</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.423982</td>\n",
       "      <td>0.618562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4.319534</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>0.355751</td>\n",
       "      <td>0.506049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>efficientnet_b1</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4.088950</td>\n",
       "      <td>0.328333</td>\n",
       "      <td>0.353924</td>\n",
       "      <td>0.509369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name  partition optimizer  batch_size  lr_init      loss  \\\n",
       "176  efficientnet_b1       test     AdamW          32   0.0010  1.168047   \n",
       "168  efficientnet_b1  test-last  NovoGrad           4   0.0010  1.015031   \n",
       "174  efficientnet_b1  test-last      Adam          32   0.0010  1.207058   \n",
       "167  efficientnet_b1       test  NovoGrad           4   0.0010  0.967837   \n",
       "177  efficientnet_b1  test-last     AdamW          32   0.0010  1.146235   \n",
       "173  efficientnet_b1       test      Adam          32   0.0010  0.998059   \n",
       "159  efficientnet_b1  test-last      Adam           4   0.0010  1.281885   \n",
       "183  efficientnet_b1  test-last  NovoGrad          32   0.0010  1.392630   \n",
       "155  efficientnet_b1       test       SGD           4   0.0010  0.963142   \n",
       "156  efficientnet_b1  test-last       SGD           4   0.0010  0.953854   \n",
       "171  efficientnet_b1  test-last       SGD          32   0.0010  1.338723   \n",
       "725  efficientnet_b1  test-last     AdamW           8   0.0001  1.060995   \n",
       "182  efficientnet_b1       test  NovoGrad          32   0.0010  1.419632   \n",
       "727  efficientnet_b1       test     AdamW          16   0.0001  1.224814   \n",
       "716  efficientnet_b1  test-last      Adam           8   0.0001  1.143181   \n",
       "719  efficientnet_b1  test-last      Adam          16   0.0001  1.214060   \n",
       "728  efficientnet_b1  test-last     AdamW          16   0.0001  1.203934   \n",
       "721  efficientnet_b1       test      Adam          32   0.0001  1.441309   \n",
       "724  efficientnet_b1       test     AdamW           8   0.0001  1.019405   \n",
       "718  efficientnet_b1       test      Adam          16   0.0001  1.308116   \n",
       "162  efficientnet_b1  test-last     AdamW           4   0.0010  1.622203   \n",
       "189  efficientnet_b1  test-last      Adam          32   0.0001  1.491638   \n",
       "715  efficientnet_b1       test      Adam           8   0.0001  1.132541   \n",
       "722  efficientnet_b1  test-last      Adam          32   0.0001  1.412577   \n",
       "158  efficientnet_b1       test      Adam           4   0.0010  0.920230   \n",
       "161  efficientnet_b1       test     AdamW           4   0.0010  1.134733   \n",
       "188  efficientnet_b1       test      Adam          32   0.0001  1.458906   \n",
       "170  efficientnet_b1       test       SGD          32   0.0010  1.385814   \n",
       "191  efficientnet_b1       test     AdamW          32   0.0001  1.581210   \n",
       "192  efficientnet_b1  test-last     AdamW          32   0.0001  1.570435   \n",
       "198  efficientnet_b1  test-last  NovoGrad          32   0.0001  1.899000   \n",
       "197  efficientnet_b1       test  NovoGrad          32   0.0001  1.979433   \n",
       "186  efficientnet_b1  test-last       SGD          32   0.0001  2.112760   \n",
       "180  efficientnet_b1  test-last  Adadelta          32   0.0010  2.413231   \n",
       "185  efficientnet_b1       test       SGD          32   0.0001  2.057528   \n",
       "179  efficientnet_b1       test  Adadelta          32   0.0010  2.544599   \n",
       "164  efficientnet_b1       test  Adadelta           4   0.0010  2.071319   \n",
       "165  efficientnet_b1  test-last  Adadelta           4   0.0010  2.117463   \n",
       "195  efficientnet_b1  test-last  Adadelta          32   0.0001  4.319534   \n",
       "194  efficientnet_b1       test  Adadelta          32   0.0001  4.088950   \n",
       "\n",
       "     accuracy  balanced_accuracy       auc  \n",
       "176  0.695000           0.691362  0.846854  \n",
       "168  0.746667           0.685350  0.854534  \n",
       "174  0.733333           0.685131  0.850821  \n",
       "167  0.723333           0.675768  0.844506  \n",
       "177  0.725000           0.674887  0.850072  \n",
       "173  0.703333           0.669572  0.846367  \n",
       "159  0.745000           0.665077  0.849811  \n",
       "183  0.676667           0.641452  0.820993  \n",
       "155  0.738333           0.638840  0.828396  \n",
       "156  0.716667           0.638109  0.823161  \n",
       "171  0.700000           0.637320  0.793081  \n",
       "725  0.698333           0.635889  0.826325  \n",
       "182  0.670000           0.635767  0.816499  \n",
       "727  0.685000           0.635397  0.819998  \n",
       "716  0.676667           0.630010  0.809808  \n",
       "719  0.691667           0.627659  0.819401  \n",
       "728  0.695000           0.627063  0.821680  \n",
       "721  0.655000           0.627007  0.787762  \n",
       "724  0.695000           0.625626  0.823367  \n",
       "718  0.658333           0.622701  0.807495  \n",
       "162  0.706667           0.621578  0.832496  \n",
       "189  0.631667           0.613695  0.780426  \n",
       "715  0.675000           0.612029  0.811827  \n",
       "722  0.656667           0.610994  0.790098  \n",
       "158  0.673333           0.610870  0.805517  \n",
       "161  0.658333           0.610676  0.820274  \n",
       "188  0.645000           0.609039  0.776103  \n",
       "170  0.636667           0.592521  0.768265  \n",
       "191  0.646667           0.589043  0.788684  \n",
       "192  0.651667           0.585877  0.788642  \n",
       "198  0.555000           0.543248  0.711129  \n",
       "197  0.526667           0.536833  0.705909  \n",
       "186  0.516667           0.514882  0.684409  \n",
       "180  0.488333           0.511613  0.676766  \n",
       "185  0.525000           0.504845  0.676767  \n",
       "179  0.451667           0.477238  0.664129  \n",
       "164  0.425000           0.429984  0.612907  \n",
       "165  0.430000           0.423982  0.618562  \n",
       "195  0.308333           0.355751  0.506049  \n",
       "194  0.328333           0.353924  0.509369  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'efficientnet_b1'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# AdamW 32 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.070402</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>0.681401</td>\n",
       "      <td>0.853872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.219412</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.680883</td>\n",
       "      <td>0.833015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.135544</td>\n",
       "      <td>0.728333</td>\n",
       "      <td>0.672019</td>\n",
       "      <td>0.865564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.057317</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.667906</td>\n",
       "      <td>0.857969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.354037</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.661458</td>\n",
       "      <td>0.855626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.336873</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.658602</td>\n",
       "      <td>0.856852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.462210</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.655980</td>\n",
       "      <td>0.838058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.698333</td>\n",
       "      <td>0.654479</td>\n",
       "      <td>0.829986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.373718</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.647933</td>\n",
       "      <td>0.811871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.135566</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.635293</td>\n",
       "      <td>0.827702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.990590</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.630330</td>\n",
       "      <td>0.787758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.365731</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.628223</td>\n",
       "      <td>0.804934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.365768</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.622720</td>\n",
       "      <td>0.809745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.444710</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.622590</td>\n",
       "      <td>0.787686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.439945</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.615752</td>\n",
       "      <td>0.801494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.167079</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.611174</td>\n",
       "      <td>0.825673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.954754</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.598123</td>\n",
       "      <td>0.770877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.522048</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.597790</td>\n",
       "      <td>0.779051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.442921</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.587166</td>\n",
       "      <td>0.753142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.449064</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.581488</td>\n",
       "      <td>0.750359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.908603</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.577756</td>\n",
       "      <td>0.787549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.994585</td>\n",
       "      <td>0.688333</td>\n",
       "      <td>0.571688</td>\n",
       "      <td>0.798418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2.073406</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.480405</td>\n",
       "      <td>0.665209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.637125</td>\n",
       "      <td>0.518333</td>\n",
       "      <td>0.476899</td>\n",
       "      <td>0.669934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.605215</td>\n",
       "      <td>0.528333</td>\n",
       "      <td>0.476840</td>\n",
       "      <td>0.651165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2.096358</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.471049</td>\n",
       "      <td>0.661717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.819133</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.470062</td>\n",
       "      <td>0.663527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.815561</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.468080</td>\n",
       "      <td>0.670591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.487632</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.353196</td>\n",
       "      <td>0.539500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>efficientnet_b2</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.467948</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.352639</td>\n",
       "      <td>0.544514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name  partition optimizer  batch_size  lr_init      loss  \\\n",
       "212  efficientnet_b2       test  NovoGrad           4   0.0010  1.070402   \n",
       "207  efficientnet_b2  test-last     AdamW           4   0.0010  1.219412   \n",
       "222  efficientnet_b2  test-last     AdamW          32   0.0010  1.135544   \n",
       "213  efficientnet_b2  test-last  NovoGrad           4   0.0010  1.057317   \n",
       "218  efficientnet_b2       test      Adam          32   0.0010  1.354037   \n",
       "219  efficientnet_b2  test-last      Adam          32   0.0010  1.336873   \n",
       "204  efficientnet_b2  test-last      Adam           4   0.0010  1.462210   \n",
       "203  efficientnet_b2       test      Adam           4   0.0010  0.838462   \n",
       "234  efficientnet_b2  test-last      Adam          32   0.0001  1.373718   \n",
       "216  efficientnet_b2  test-last       SGD          32   0.0010  1.135566   \n",
       "221  efficientnet_b2       test     AdamW          32   0.0010  0.990590   \n",
       "227  efficientnet_b2       test  NovoGrad          32   0.0010  1.365731   \n",
       "233  efficientnet_b2       test      Adam          32   0.0001  1.365768   \n",
       "237  efficientnet_b2  test-last     AdamW          32   0.0001  1.444710   \n",
       "228  efficientnet_b2  test-last  NovoGrad          32   0.0010  1.439945   \n",
       "215  efficientnet_b2       test       SGD          32   0.0010  1.167079   \n",
       "206  efficientnet_b2       test     AdamW           4   0.0010  0.954754   \n",
       "236  efficientnet_b2       test     AdamW          32   0.0001  1.522048   \n",
       "230  efficientnet_b2       test       SGD          32   0.0001  1.442921   \n",
       "231  efficientnet_b2  test-last       SGD          32   0.0001  1.449064   \n",
       "200  efficientnet_b2       test       SGD           4   0.0010  0.908603   \n",
       "201  efficientnet_b2  test-last       SGD           4   0.0010  0.994585   \n",
       "224  efficientnet_b2       test  Adadelta          32   0.0010  2.073406   \n",
       "210  efficientnet_b2  test-last  Adadelta           4   0.0010  1.637125   \n",
       "209  efficientnet_b2       test  Adadelta           4   0.0010  1.605215   \n",
       "225  efficientnet_b2  test-last  Adadelta          32   0.0010  2.096358   \n",
       "242  efficientnet_b2       test  NovoGrad          32   0.0001  1.819133   \n",
       "243  efficientnet_b2  test-last  NovoGrad          32   0.0001  1.815561   \n",
       "240  efficientnet_b2  test-last  Adadelta          32   0.0001  2.487632   \n",
       "239  efficientnet_b2       test  Adadelta          32   0.0001  2.467948   \n",
       "\n",
       "     accuracy  balanced_accuracy       auc  \n",
       "212  0.738333           0.681401  0.853872  \n",
       "207  0.726667           0.680883  0.833015  \n",
       "222  0.728333           0.672019  0.865564  \n",
       "213  0.751667           0.667906  0.857969  \n",
       "218  0.726667           0.661458  0.855626  \n",
       "219  0.726667           0.658602  0.856852  \n",
       "204  0.736667           0.655980  0.838058  \n",
       "203  0.698333           0.654479  0.829986  \n",
       "234  0.693333           0.647933  0.811871  \n",
       "216  0.706667           0.635293  0.827702  \n",
       "221  0.620000           0.630330  0.787758  \n",
       "227  0.691667           0.628223  0.804934  \n",
       "233  0.653333           0.622720  0.809745  \n",
       "237  0.676667           0.622590  0.787686  \n",
       "228  0.671667           0.615752  0.801494  \n",
       "215  0.675000           0.611174  0.825673  \n",
       "206  0.595000           0.598123  0.770877  \n",
       "236  0.665000           0.597790  0.779051  \n",
       "230  0.625000           0.587166  0.753142  \n",
       "231  0.616667           0.581488  0.750359  \n",
       "200  0.671667           0.577756  0.787549  \n",
       "201  0.688333           0.571688  0.798418  \n",
       "224  0.446667           0.480405  0.665209  \n",
       "210  0.518333           0.476899  0.669934  \n",
       "209  0.528333           0.476840  0.651165  \n",
       "225  0.435000           0.471049  0.661717  \n",
       "242  0.513333           0.470062  0.663527  \n",
       "243  0.508333           0.468080  0.670591  \n",
       "240  0.410000           0.353196  0.539500  \n",
       "239  0.408333           0.352639  0.544514  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'efficientnet_b2'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# AdamW 32 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.094608</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>0.728125</td>\n",
       "      <td>0.883634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.028434</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.722031</td>\n",
       "      <td>0.888774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.127822</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.721281</td>\n",
       "      <td>0.884606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.965470</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.687623</td>\n",
       "      <td>0.862472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.034839</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.682190</td>\n",
       "      <td>0.856159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.289731</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.670414</td>\n",
       "      <td>0.850493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.639891</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.652861</td>\n",
       "      <td>0.820242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.155916</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.643859</td>\n",
       "      <td>0.820416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.951674</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.637574</td>\n",
       "      <td>0.799307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.053663</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.633416</td>\n",
       "      <td>0.820249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.024002</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.632392</td>\n",
       "      <td>0.829142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.955042</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.625678</td>\n",
       "      <td>0.818927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.365609</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>0.621668</td>\n",
       "      <td>0.827880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.073813</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.616722</td>\n",
       "      <td>0.818947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.977213</td>\n",
       "      <td>0.681667</td>\n",
       "      <td>0.606292</td>\n",
       "      <td>0.801270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.154166</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.604395</td>\n",
       "      <td>0.801762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.085831</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.604239</td>\n",
       "      <td>0.817201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.839648</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.596720</td>\n",
       "      <td>0.815798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.152876</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.578417</td>\n",
       "      <td>0.786675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.211943</td>\n",
       "      <td>0.668333</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.788311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.397118</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.559681</td>\n",
       "      <td>0.736858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.357600</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.557337</td>\n",
       "      <td>0.734680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.377864</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.536843</td>\n",
       "      <td>0.705118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.377864</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.536843</td>\n",
       "      <td>0.705118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.773872</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.521772</td>\n",
       "      <td>0.688637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.763318</td>\n",
       "      <td>0.518333</td>\n",
       "      <td>0.521170</td>\n",
       "      <td>0.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3.563922</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.481751</td>\n",
       "      <td>0.640677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.476011</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.446337</td>\n",
       "      <td>0.618290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3.197752</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.369168</td>\n",
       "      <td>0.503308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>efficientnet_b3</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3.182075</td>\n",
       "      <td>0.298333</td>\n",
       "      <td>0.353226</td>\n",
       "      <td>0.498900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name  partition optimizer  batch_size  lr_init      loss  \\\n",
       "264  efficientnet_b3  test-last      Adam          32   0.0010  1.094608   \n",
       "267  efficientnet_b3  test-last     AdamW          32   0.0010  1.028434   \n",
       "263  efficientnet_b3       test      Adam          32   0.0010  1.127822   \n",
       "257  efficientnet_b3       test  NovoGrad           4   0.0010  0.965470   \n",
       "258  efficientnet_b3  test-last  NovoGrad           4   0.0010  1.034839   \n",
       "266  efficientnet_b3       test     AdamW          32   0.0010  1.289731   \n",
       "282  efficientnet_b3  test-last     AdamW          32   0.0001  1.639891   \n",
       "273  efficientnet_b3  test-last  NovoGrad          32   0.0010  1.155916   \n",
       "248  efficientnet_b3       test      Adam           4   0.0010  0.951674   \n",
       "281  efficientnet_b3       test     AdamW          32   0.0001  1.053663   \n",
       "251  efficientnet_b3       test     AdamW           4   0.0010  1.024002   \n",
       "246  efficientnet_b3  test-last       SGD           4   0.0010  0.955042   \n",
       "249  efficientnet_b3  test-last      Adam           4   0.0010  1.365609   \n",
       "279  efficientnet_b3  test-last      Adam          32   0.0001  1.073813   \n",
       "245  efficientnet_b3       test       SGD           4   0.0010  0.977213   \n",
       "261  efficientnet_b3  test-last       SGD          32   0.0010  1.154166   \n",
       "278  efficientnet_b3       test      Adam          32   0.0001  1.085831   \n",
       "252  efficientnet_b3  test-last     AdamW           4   0.0010  1.839648   \n",
       "260  efficientnet_b3       test       SGD          32   0.0010  1.152876   \n",
       "272  efficientnet_b3       test  NovoGrad          32   0.0010  1.211943   \n",
       "275  efficientnet_b3       test       SGD          32   0.0001  1.397118   \n",
       "276  efficientnet_b3  test-last       SGD          32   0.0001  1.357600   \n",
       "287  efficientnet_b3       test  NovoGrad          32   0.0001  1.377864   \n",
       "288  efficientnet_b3  test-last  NovoGrad          32   0.0001  1.377864   \n",
       "270  efficientnet_b3  test-last  Adadelta          32   0.0010  1.773872   \n",
       "269  efficientnet_b3       test  Adadelta          32   0.0010  1.763318   \n",
       "255  efficientnet_b3  test-last  Adadelta           4   0.0010  3.563922   \n",
       "254  efficientnet_b3       test  Adadelta           4   0.0010  1.476011   \n",
       "284  efficientnet_b3       test  Adadelta          32   0.0001  3.197752   \n",
       "285  efficientnet_b3  test-last  Adadelta          32   0.0001  3.182075   \n",
       "\n",
       "     accuracy  balanced_accuracy       auc  \n",
       "264  0.761667           0.728125  0.883634  \n",
       "267  0.780000           0.722031  0.888774  \n",
       "263  0.758333           0.721281  0.884606  \n",
       "257  0.746667           0.687623  0.862472  \n",
       "258  0.750000           0.682190  0.856159  \n",
       "266  0.716667           0.670414  0.850493  \n",
       "282  0.680000           0.652861  0.820242  \n",
       "273  0.706667           0.643859  0.820416  \n",
       "248  0.650000           0.637574  0.799307  \n",
       "281  0.685000           0.633416  0.820249  \n",
       "251  0.713333           0.632392  0.829142  \n",
       "246  0.691667           0.625678  0.818927  \n",
       "249  0.743333           0.621668  0.827880  \n",
       "279  0.706667           0.616722  0.818947  \n",
       "245  0.681667           0.606292  0.801270  \n",
       "261  0.660000           0.604395  0.801762  \n",
       "278  0.690000           0.604239  0.817201  \n",
       "252  0.705000           0.596720  0.815798  \n",
       "260  0.656667           0.578417  0.786675  \n",
       "272  0.668333           0.576623  0.788311  \n",
       "275  0.580000           0.559681  0.736858  \n",
       "276  0.593333           0.557337  0.734680  \n",
       "287  0.578333           0.536843  0.705118  \n",
       "288  0.578333           0.536843  0.705118  \n",
       "270  0.513333           0.521772  0.688637  \n",
       "269  0.518333           0.521170  0.693000  \n",
       "255  0.465000           0.481751  0.640677  \n",
       "254  0.515000           0.446337  0.618290  \n",
       "284  0.310000           0.369168  0.503308  \n",
       "285  0.298333           0.353226  0.498900  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'efficientnet_b3'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# Adam 32 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.908873</td>\n",
       "      <td>0.781667</td>\n",
       "      <td>0.727444</td>\n",
       "      <td>0.882717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.049110</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.711276</td>\n",
       "      <td>0.871630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.700541</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>0.706809</td>\n",
       "      <td>0.847848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.170629</td>\n",
       "      <td>0.768333</td>\n",
       "      <td>0.694667</td>\n",
       "      <td>0.870567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.447555</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.683932</td>\n",
       "      <td>0.862220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.107901</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>0.678817</td>\n",
       "      <td>0.852581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.862355</td>\n",
       "      <td>0.711667</td>\n",
       "      <td>0.670938</td>\n",
       "      <td>0.858743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.763660</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.661732</td>\n",
       "      <td>0.852013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2.356490</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.661504</td>\n",
       "      <td>0.840422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.929963</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.649577</td>\n",
       "      <td>0.827444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>15.875946</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.647905</td>\n",
       "      <td>0.843180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.886805</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.639799</td>\n",
       "      <td>0.841354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.062648</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.638714</td>\n",
       "      <td>0.842584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.990017</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.635895</td>\n",
       "      <td>0.829034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.892401</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.631959</td>\n",
       "      <td>0.828644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.766983</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>0.803562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.118037</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.610598</td>\n",
       "      <td>0.812517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.253158</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.595089</td>\n",
       "      <td>0.812976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.938354</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.566208</td>\n",
       "      <td>0.754466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.916092</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.554494</td>\n",
       "      <td>0.755710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.043045</td>\n",
       "      <td>0.538333</td>\n",
       "      <td>0.541352</td>\n",
       "      <td>0.711587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.095202</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.532424</td>\n",
       "      <td>0.697770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.156080</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.506518</td>\n",
       "      <td>0.678109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.198845</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.471223</td>\n",
       "      <td>0.660749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.373794</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.439775</td>\n",
       "      <td>0.582411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.428065</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.430743</td>\n",
       "      <td>0.575494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.448107</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>0.376010</td>\n",
       "      <td>0.547150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.443075</td>\n",
       "      <td>0.353333</td>\n",
       "      <td>0.363209</td>\n",
       "      <td>0.541767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.501769</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.317346</td>\n",
       "      <td>0.476331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>efficientnet_b4</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.504635</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.287147</td>\n",
       "      <td>0.467109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name  partition optimizer  batch_size  lr_init       loss  \\\n",
       "447  efficientnet_b4  test-last      Adam          25   0.0010   0.908873   \n",
       "450  efficientnet_b4  test-last     AdamW          25   0.0010   1.049110   \n",
       "291  efficientnet_b4  test-last       SGD           4   0.0010   0.700541   \n",
       "294  efficientnet_b4  test-last      Adam           4   0.0010   1.170629   \n",
       "297  efficientnet_b4  test-last     AdamW           4   0.0010   1.447555   \n",
       "296  efficientnet_b4       test     AdamW           4   0.0010   1.107901   \n",
       "293  efficientnet_b4       test      Adam           4   0.0010   0.862355   \n",
       "446  efficientnet_b4       test      Adam          25   0.0010   0.763660   \n",
       "302  efficientnet_b4       test  NovoGrad           4   0.0010   2.356490   \n",
       "461  efficientnet_b4       test      Adam          25   0.0001   0.929963   \n",
       "303  efficientnet_b4  test-last  NovoGrad           4   0.0010  15.875946   \n",
       "465  efficientnet_b4  test-last     AdamW          25   0.0001   0.886805   \n",
       "449  efficientnet_b4       test     AdamW          25   0.0010   1.062648   \n",
       "462  efficientnet_b4  test-last      Adam          25   0.0001   0.990017   \n",
       "464  efficientnet_b4       test     AdamW          25   0.0001   0.892401   \n",
       "290  efficientnet_b4       test       SGD           4   0.0010   0.766983   \n",
       "455  efficientnet_b4       test  NovoGrad          25   0.0010   1.118037   \n",
       "456  efficientnet_b4  test-last  NovoGrad          25   0.0010   1.253158   \n",
       "443  efficientnet_b4       test       SGD          25   0.0010   0.938354   \n",
       "444  efficientnet_b4  test-last       SGD          25   0.0010   0.916092   \n",
       "300  efficientnet_b4  test-last  Adadelta           4   0.0010   1.043045   \n",
       "299  efficientnet_b4       test  Adadelta           4   0.0010   1.095202   \n",
       "471  efficientnet_b4  test-last  NovoGrad          25   0.0001   1.156080   \n",
       "470  efficientnet_b4       test  NovoGrad          25   0.0001   1.198845   \n",
       "459  efficientnet_b4  test-last       SGD          25   0.0001   1.373794   \n",
       "458  efficientnet_b4       test       SGD          25   0.0001   1.428065   \n",
       "453  efficientnet_b4  test-last  Adadelta          25   0.0010   1.448107   \n",
       "452  efficientnet_b4       test  Adadelta          25   0.0010   1.443075   \n",
       "468  efficientnet_b4  test-last  Adadelta          25   0.0001   1.501769   \n",
       "467  efficientnet_b4       test  Adadelta          25   0.0001   1.504635   \n",
       "\n",
       "     accuracy  balanced_accuracy       auc  \n",
       "447  0.781667           0.727444  0.882717  \n",
       "450  0.758333           0.711276  0.871630  \n",
       "291  0.743333           0.706809  0.847848  \n",
       "294  0.768333           0.694667  0.870567  \n",
       "297  0.746667           0.683932  0.862220  \n",
       "296  0.738333           0.678817  0.852581  \n",
       "293  0.711667           0.670938  0.858743  \n",
       "446  0.676667           0.661732  0.852013  \n",
       "302  0.720000           0.661504  0.840422  \n",
       "461  0.705000           0.649577  0.827444  \n",
       "303  0.750000           0.647905  0.843180  \n",
       "465  0.716667           0.639799  0.841354  \n",
       "449  0.646667           0.638714  0.842584  \n",
       "462  0.696667           0.635895  0.829034  \n",
       "464  0.685000           0.631959  0.828644  \n",
       "290  0.685000           0.611387  0.803562  \n",
       "455  0.673333           0.610598  0.812517  \n",
       "456  0.690000           0.595089  0.812976  \n",
       "443  0.590000           0.566208  0.754466  \n",
       "444  0.590000           0.554494  0.755710  \n",
       "300  0.538333           0.541352  0.711587  \n",
       "299  0.496667           0.532424  0.697770  \n",
       "471  0.475000           0.506518  0.678109  \n",
       "470  0.450000           0.471223  0.660749  \n",
       "459  0.400000           0.439775  0.582411  \n",
       "458  0.380000           0.430743  0.575494  \n",
       "453  0.363333           0.376010  0.547150  \n",
       "452  0.353333           0.363209  0.541767  \n",
       "468  0.333333           0.317346  0.476331  \n",
       "467  0.316667           0.287147  0.467109  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'efficientnet_b4'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# Adam 25 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.989353</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.523753</td>\n",
       "      <td>0.686449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.627903</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.512516</td>\n",
       "      <td>0.695328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>6.558554</td>\n",
       "      <td>0.568333</td>\n",
       "      <td>0.508580</td>\n",
       "      <td>0.688209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>5.625076</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.508040</td>\n",
       "      <td>0.718794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.894141</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.500452</td>\n",
       "      <td>0.691918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.378714</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.499043</td>\n",
       "      <td>0.679986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.000206</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.495959</td>\n",
       "      <td>0.688488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3.727323</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.493386</td>\n",
       "      <td>0.652488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.937679</td>\n",
       "      <td>0.596667</td>\n",
       "      <td>0.477019</td>\n",
       "      <td>0.654037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.707995</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.476007</td>\n",
       "      <td>0.641778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.162862</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.452961</td>\n",
       "      <td>0.650566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3.088250</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>0.452567</td>\n",
       "      <td>0.620531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>12.021844</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.446413</td>\n",
       "      <td>0.593589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.495934</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.445358</td>\n",
       "      <td>0.634184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>6.612645</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.432389</td>\n",
       "      <td>0.586338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.215059</td>\n",
       "      <td>0.581667</td>\n",
       "      <td>0.407982</td>\n",
       "      <td>0.616548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>9.275835</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.406629</td>\n",
       "      <td>0.627075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>5.050833</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.401003</td>\n",
       "      <td>0.583651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.026744</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.394841</td>\n",
       "      <td>0.555450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>19.256675</td>\n",
       "      <td>0.421667</td>\n",
       "      <td>0.390544</td>\n",
       "      <td>0.563245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>37.069010</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.363931</td>\n",
       "      <td>0.535913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>134.124617</td>\n",
       "      <td>0.528333</td>\n",
       "      <td>0.363415</td>\n",
       "      <td>0.543019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>33.267505</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.362380</td>\n",
       "      <td>0.549615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>40.146780</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.348833</td>\n",
       "      <td>0.530582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>139.969386</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>0.337241</td>\n",
       "      <td>0.513529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>26.003258</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.332433</td>\n",
       "      <td>0.547439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150.410075</td>\n",
       "      <td>0.438333</td>\n",
       "      <td>0.325656</td>\n",
       "      <td>0.541619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>129.859527</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.325465</td>\n",
       "      <td>0.533355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>18.699204</td>\n",
       "      <td>0.396667</td>\n",
       "      <td>0.308686</td>\n",
       "      <td>0.473729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>efficientnet_b5</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>554.611479</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.280823</td>\n",
       "      <td>0.469817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name  partition optimizer  batch_size  lr_init        loss  \\\n",
       "309  efficientnet_b5  test-last      Adam           4   0.0010    0.989353   \n",
       "473  efficientnet_b5       test       SGD          10   0.0010    1.627903   \n",
       "306  efficientnet_b5  test-last       SGD           4   0.0010    6.558554   \n",
       "305  efficientnet_b5       test       SGD           4   0.0010    5.625076   \n",
       "308  efficientnet_b5       test      Adam           4   0.0010    0.894141   \n",
       "474  efficientnet_b5  test-last       SGD          10   0.0010    1.378714   \n",
       "486  efficientnet_b5  test-last     AdamW          10   0.0010    1.000206   \n",
       "489  efficientnet_b5  test-last     AdamW          10   0.0001    3.727323   \n",
       "479  efficientnet_b5       test      Adam          10   0.0010    0.937679   \n",
       "485  efficientnet_b5       test     AdamW          10   0.0010    1.707995   \n",
       "480  efficientnet_b5  test-last      Adam          10   0.0010    1.162862   \n",
       "498  efficientnet_b5  test-last  NovoGrad          10   0.0010    3.088250   \n",
       "483  efficientnet_b5  test-last      Adam          10   0.0001   12.021844   \n",
       "497  efficientnet_b5       test  NovoGrad          10   0.0010    1.495934   \n",
       "488  efficientnet_b5       test     AdamW          10   0.0001    6.612645   \n",
       "317  efficientnet_b5       test  NovoGrad           4   0.0010   10.215059   \n",
       "318  efficientnet_b5  test-last  NovoGrad           4   0.0010    9.275835   \n",
       "311  efficientnet_b5       test     AdamW           4   0.0010    5.050833   \n",
       "312  efficientnet_b5  test-last     AdamW           4   0.0010    1.026744   \n",
       "477  efficientnet_b5  test-last       SGD          10   0.0001   19.256675   \n",
       "476  efficientnet_b5       test       SGD          10   0.0001   37.069010   \n",
       "500  efficientnet_b5       test  NovoGrad          10   0.0001  134.124617   \n",
       "492  efficientnet_b5  test-last  Adadelta          10   0.0010   33.267505   \n",
       "495  efficientnet_b5  test-last  Adadelta          10   0.0001   40.146780   \n",
       "315  efficientnet_b5  test-last  Adadelta           4   0.0010  139.969386   \n",
       "491  efficientnet_b5       test  Adadelta          10   0.0010   26.003258   \n",
       "501  efficientnet_b5  test-last  NovoGrad          10   0.0001  150.410075   \n",
       "494  efficientnet_b5       test  Adadelta          10   0.0001  129.859527   \n",
       "482  efficientnet_b5       test      Adam          10   0.0001   18.699204   \n",
       "314  efficientnet_b5       test  Adadelta           4   0.0010  554.611479   \n",
       "\n",
       "     accuracy  balanced_accuracy       auc  \n",
       "309  0.508333           0.523753  0.686449  \n",
       "473  0.575000           0.512516  0.695328  \n",
       "306  0.568333           0.508580  0.688209  \n",
       "305  0.616667           0.508040  0.718794  \n",
       "308  0.595000           0.500452  0.691918  \n",
       "474  0.380000           0.499043  0.679986  \n",
       "486  0.586667           0.495959  0.688488  \n",
       "489  0.480000           0.493386  0.652488  \n",
       "479  0.596667           0.477019  0.654037  \n",
       "485  0.453333           0.476007  0.641778  \n",
       "480  0.510000           0.452961  0.650566  \n",
       "498  0.476667           0.452567  0.620531  \n",
       "483  0.391667           0.446413  0.593589  \n",
       "497  0.541667           0.445358  0.634184  \n",
       "488  0.500000           0.432389  0.586338  \n",
       "317  0.581667           0.407982  0.616548  \n",
       "318  0.570000           0.406629  0.627075  \n",
       "311  0.400000           0.401003  0.583651  \n",
       "312  0.470000           0.394841  0.555450  \n",
       "477  0.421667           0.390544  0.563245  \n",
       "476  0.426667           0.363931  0.535913  \n",
       "500  0.528333           0.363415  0.543019  \n",
       "492  0.515000           0.362380  0.549615  \n",
       "495  0.230000           0.348833  0.530582  \n",
       "315  0.565000           0.337241  0.513529  \n",
       "491  0.503333           0.332433  0.547439  \n",
       "501  0.438333           0.325656  0.541619  \n",
       "494  0.220000           0.325465  0.533355  \n",
       "482  0.396667           0.308686  0.473729  \n",
       "314  0.433333           0.280823  0.469817  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'efficientnet_b5'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# Adam 4 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>5.526674</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.524762</td>\n",
       "      <td>0.661235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4.602089</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.523060</td>\n",
       "      <td>0.664742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.872782</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.500061</td>\n",
       "      <td>0.678753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>9.178983</td>\n",
       "      <td>0.536667</td>\n",
       "      <td>0.483878</td>\n",
       "      <td>0.646566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.117122</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.482565</td>\n",
       "      <td>0.633844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4.225008</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>0.461473</td>\n",
       "      <td>0.646490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>41.322139</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.459588</td>\n",
       "      <td>0.622651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.058984</td>\n",
       "      <td>0.643333</td>\n",
       "      <td>0.457041</td>\n",
       "      <td>0.677095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.953805</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>0.455760</td>\n",
       "      <td>0.660106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>20.448613</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.453792</td>\n",
       "      <td>0.620067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.073066</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.451019</td>\n",
       "      <td>0.626502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>6.339948</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>0.449129</td>\n",
       "      <td>0.607809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.999329</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.448646</td>\n",
       "      <td>0.648383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3.769776</td>\n",
       "      <td>0.568333</td>\n",
       "      <td>0.444029</td>\n",
       "      <td>0.648440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>11.190178</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.440108</td>\n",
       "      <td>0.609303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>18.488261</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.431500</td>\n",
       "      <td>0.625039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>493.570738</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.431211</td>\n",
       "      <td>0.592468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>143.931061</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>0.430930</td>\n",
       "      <td>0.582904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>320.958505</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.425474</td>\n",
       "      <td>0.592194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.009744</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.395733</td>\n",
       "      <td>0.588608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>9.600096</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.376682</td>\n",
       "      <td>0.577181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.037499</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.363933</td>\n",
       "      <td>0.565435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2365.026892</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.361828</td>\n",
       "      <td>0.529067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1075.767243</td>\n",
       "      <td>0.478333</td>\n",
       "      <td>0.350247</td>\n",
       "      <td>0.549213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>739.777643</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.349323</td>\n",
       "      <td>0.541855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3113.814308</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.527691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2944.140590</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.334930</td>\n",
       "      <td>0.497185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1142.940943</td>\n",
       "      <td>0.456667</td>\n",
       "      <td>0.324671</td>\n",
       "      <td>0.539413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1526.609094</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.320828</td>\n",
       "      <td>0.513034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>efficientnet_b6</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>754.664028</td>\n",
       "      <td>0.461667</td>\n",
       "      <td>0.305478</td>\n",
       "      <td>0.488025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name  partition optimizer  batch_size  lr_init         loss  \\\n",
       "321  efficientnet_b6  test-last       SGD           4   0.0010     5.526674   \n",
       "320  efficientnet_b6       test       SGD           4   0.0010     4.602089   \n",
       "326  efficientnet_b6       test     AdamW           4   0.0010     0.872782   \n",
       "335  efficientnet_b6       test  NovoGrad           4   0.0010     9.178983   \n",
       "516  efficientnet_b6  test-last     AdamW           5   0.0010     1.117122   \n",
       "512  efficientnet_b6       test      Adam           5   0.0001     4.225008   \n",
       "519  efficientnet_b6  test-last     AdamW           5   0.0001    41.322139   \n",
       "509  efficientnet_b6       test      Adam           5   0.0010     1.058984   \n",
       "327  efficientnet_b6  test-last     AdamW           4   0.0010     0.953805   \n",
       "513  efficientnet_b6  test-last      Adam           5   0.0001    20.448613   \n",
       "323  efficientnet_b6       test      Adam           4   0.0010     1.073066   \n",
       "504  efficientnet_b6  test-last       SGD           5   0.0010     6.339948   \n",
       "324  efficientnet_b6  test-last      Adam           4   0.0010     0.999329   \n",
       "503  efficientnet_b6       test       SGD           5   0.0010     3.769776   \n",
       "336  efficientnet_b6  test-last  NovoGrad           4   0.0010    11.190178   \n",
       "528  efficientnet_b6  test-last  NovoGrad           5   0.0010    18.488261   \n",
       "507  efficientnet_b6  test-last       SGD           5   0.0001   493.570738   \n",
       "518  efficientnet_b6       test     AdamW           5   0.0001   143.931061   \n",
       "506  efficientnet_b6       test       SGD           5   0.0001   320.958505   \n",
       "510  efficientnet_b6  test-last      Adam           5   0.0010     1.009744   \n",
       "527  efficientnet_b6       test  NovoGrad           5   0.0010     9.600096   \n",
       "515  efficientnet_b6       test     AdamW           5   0.0010     1.037499   \n",
       "525  efficientnet_b6  test-last  Adadelta           5   0.0001  2365.026892   \n",
       "530  efficientnet_b6       test  NovoGrad           5   0.0001  1075.767243   \n",
       "531  efficientnet_b6  test-last  NovoGrad           5   0.0001   739.777643   \n",
       "330  efficientnet_b6  test-last  Adadelta           4   0.0010  3113.814308   \n",
       "329  efficientnet_b6       test  Adadelta           4   0.0010  2944.140590   \n",
       "522  efficientnet_b6  test-last  Adadelta           5   0.0010  1142.940943   \n",
       "524  efficientnet_b6       test  Adadelta           5   0.0001  1526.609094   \n",
       "521  efficientnet_b6       test  Adadelta           5   0.0010   754.664028   \n",
       "\n",
       "     accuracy  balanced_accuracy       auc  \n",
       "321  0.533333           0.524762  0.661235  \n",
       "320  0.526667           0.523060  0.664742  \n",
       "326  0.665000           0.500061  0.678753  \n",
       "335  0.536667           0.483878  0.646566  \n",
       "516  0.525000           0.482565  0.633844  \n",
       "512  0.563333           0.461473  0.646490  \n",
       "519  0.440000           0.459588  0.622651  \n",
       "509  0.643333           0.457041  0.677095  \n",
       "327  0.618333           0.455760  0.660106  \n",
       "513  0.451667           0.453792  0.620067  \n",
       "323  0.485000           0.451019  0.626502  \n",
       "504  0.471667           0.449129  0.607809  \n",
       "324  0.560000           0.448646  0.648383  \n",
       "503  0.568333           0.444029  0.648440  \n",
       "336  0.493333           0.440108  0.609303  \n",
       "528  0.558333           0.431500  0.625039  \n",
       "507  0.508333           0.431211  0.592468  \n",
       "518  0.565000           0.430930  0.582904  \n",
       "506  0.510000           0.425474  0.592194  \n",
       "510  0.520000           0.395733  0.588608  \n",
       "527  0.558333           0.376682  0.577181  \n",
       "515  0.535000           0.363933  0.565435  \n",
       "525  0.250000           0.361828  0.529067  \n",
       "530  0.478333           0.350247  0.549213  \n",
       "531  0.446667           0.349323  0.541855  \n",
       "330  0.460000           0.346667  0.527691  \n",
       "329  0.406667           0.334930  0.497185  \n",
       "522  0.456667           0.324671  0.539413  \n",
       "524  0.228333           0.320828  0.513034  \n",
       "521  0.461667           0.305478  0.488025  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'efficientnet_b6'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# SGD 4 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_name, partition, optimizer, batch_size, lr_init, loss, accuracy, balanced_accuracy, auc]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'efficientnet_b7'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# SGD 4 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.184861</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>0.716813</td>\n",
       "      <td>0.861600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.099426</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.715693</td>\n",
       "      <td>0.863376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.123392</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>0.711685</td>\n",
       "      <td>0.861792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.255717</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.707736</td>\n",
       "      <td>0.859565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.442460</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>0.698534</td>\n",
       "      <td>0.860863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.157961</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.695479</td>\n",
       "      <td>0.866523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.033673</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.686860</td>\n",
       "      <td>0.846667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.773989</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>0.673630</td>\n",
       "      <td>0.841894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.983708</td>\n",
       "      <td>0.721667</td>\n",
       "      <td>0.672628</td>\n",
       "      <td>0.862407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.815839</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.671462</td>\n",
       "      <td>0.840184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.759495</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.669457</td>\n",
       "      <td>0.833204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.340500</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.664727</td>\n",
       "      <td>0.853021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.991459</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.659833</td>\n",
       "      <td>0.853404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.371429</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.649464</td>\n",
       "      <td>0.804544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.826276</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.643203</td>\n",
       "      <td>0.829352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.819291</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.633249</td>\n",
       "      <td>0.820946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.263632</td>\n",
       "      <td>0.668333</td>\n",
       "      <td>0.631791</td>\n",
       "      <td>0.777020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.947619</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.616981</td>\n",
       "      <td>0.790103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.941768</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.607864</td>\n",
       "      <td>0.776039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.242871</td>\n",
       "      <td>0.638333</td>\n",
       "      <td>0.600789</td>\n",
       "      <td>0.771696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.123520</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.597262</td>\n",
       "      <td>0.770942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.961407</td>\n",
       "      <td>0.528333</td>\n",
       "      <td>0.596229</td>\n",
       "      <td>0.776231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.289378</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.580783</td>\n",
       "      <td>0.768698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.840100</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.575842</td>\n",
       "      <td>0.776019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.094662</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.383121</td>\n",
       "      <td>0.568681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.159669</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.362972</td>\n",
       "      <td>0.519594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.161454</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.355558</td>\n",
       "      <td>0.512312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.069572</td>\n",
       "      <td>0.648333</td>\n",
       "      <td>0.331941</td>\n",
       "      <td>0.531699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.096732</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.330071</td>\n",
       "      <td>0.558870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>resnest101e</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>5.190309</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.308142</td>\n",
       "      <td>0.462924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name  partition optimizer  batch_size  lr_init      loss  \\\n",
       "389  resnest101e       test     AdamW          32   0.0001  1.184861   \n",
       "386  resnest101e       test      Adam          32   0.0001  1.099426   \n",
       "387  resnest101e  test-last      Adam          32   0.0001  1.123392   \n",
       "390  resnest101e  test-last     AdamW          32   0.0001  1.255717   \n",
       "366  resnest101e  test-last  NovoGrad           4   0.0010  1.442460   \n",
       "381  resnest101e  test-last  NovoGrad          32   0.0010  1.157961   \n",
       "354  resnest101e  test-last       SGD           4   0.0010  1.033673   \n",
       "396  resnest101e  test-last  NovoGrad          32   0.0001  0.773989   \n",
       "369  resnest101e  test-last       SGD          32   0.0010  0.983708   \n",
       "395  resnest101e       test  NovoGrad          32   0.0001  0.815839   \n",
       "362  resnest101e       test  Adadelta           4   0.0010  0.759495   \n",
       "365  resnest101e       test  NovoGrad           4   0.0010  1.340500   \n",
       "368  resnest101e       test       SGD          32   0.0010  0.991459   \n",
       "380  resnest101e       test  NovoGrad          32   0.0010  1.371429   \n",
       "363  resnest101e  test-last  Adadelta           4   0.0010  0.826276   \n",
       "384  resnest101e  test-last       SGD          32   0.0001  0.819291   \n",
       "375  resnest101e  test-last     AdamW          32   0.0010  1.263632   \n",
       "383  resnest101e       test       SGD          32   0.0001  0.947619   \n",
       "377  resnest101e       test  Adadelta          32   0.0010  0.941768   \n",
       "374  resnest101e       test     AdamW          32   0.0010  1.242871   \n",
       "372  resnest101e  test-last      Adam          32   0.0010  1.123520   \n",
       "378  resnest101e  test-last  Adadelta          32   0.0010  0.961407   \n",
       "353  resnest101e       test       SGD           4   0.0010  1.289378   \n",
       "371  resnest101e       test      Adam          32   0.0010  0.840100   \n",
       "357  resnest101e  test-last      Adam           4   0.0010  1.094662   \n",
       "393  resnest101e  test-last  Adadelta          32   0.0001  1.159669   \n",
       "392  resnest101e       test  Adadelta          32   0.0001  1.161454   \n",
       "360  resnest101e  test-last     AdamW           4   0.0010  1.069572   \n",
       "359  resnest101e       test     AdamW           4   0.0010  1.096732   \n",
       "356  resnest101e       test      Adam           4   0.0010  5.190309   \n",
       "\n",
       "     accuracy  balanced_accuracy       auc  \n",
       "389  0.738333           0.716813  0.861600  \n",
       "386  0.736667           0.715693  0.863376  \n",
       "387  0.738333           0.711685  0.861792  \n",
       "390  0.725000           0.707736  0.859565  \n",
       "366  0.738333           0.698534  0.860863  \n",
       "381  0.725000           0.695479  0.866523  \n",
       "354  0.733333           0.686860  0.846667  \n",
       "396  0.748333           0.673630  0.841894  \n",
       "369  0.721667           0.672628  0.862407  \n",
       "395  0.726667           0.671462  0.840184  \n",
       "362  0.673333           0.669457  0.833204  \n",
       "365  0.755000           0.664727  0.853021  \n",
       "368  0.710000           0.659833  0.853404  \n",
       "380  0.620000           0.649464  0.804544  \n",
       "363  0.611667           0.643203  0.829352  \n",
       "384  0.658333           0.633249  0.820946  \n",
       "375  0.668333           0.631791  0.777020  \n",
       "383  0.546667           0.616981  0.790103  \n",
       "377  0.543333           0.607864  0.776039  \n",
       "374  0.638333           0.600789  0.771696  \n",
       "372  0.606667           0.597262  0.770942  \n",
       "378  0.528333           0.596229  0.776231  \n",
       "353  0.578333           0.580783  0.768698  \n",
       "371  0.595000           0.575842  0.776019  \n",
       "357  0.635000           0.383121  0.568681  \n",
       "393  0.285000           0.362972  0.519594  \n",
       "392  0.283333           0.355558  0.512312  \n",
       "360  0.648333           0.331941  0.531699  \n",
       "359  0.625000           0.330071  0.558870  \n",
       "356  0.555000           0.308142  0.462924  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'resnest101e'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# AdamW 32 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>seresnext101_32x8d</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.287907</td>\n",
       "      <td>0.728333</td>\n",
       "      <td>0.656595</td>\n",
       "      <td>0.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>seresnext101_32x8d</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.986254</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.628410</td>\n",
       "      <td>0.815344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>seresnext101_32x8d</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.826894</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.628355</td>\n",
       "      <td>0.816871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>seresnext101_32x8d</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.826894</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.628355</td>\n",
       "      <td>0.816871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>seresnext101_32x8d</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.901108</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.604739</td>\n",
       "      <td>0.779208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>seresnext101_32x8d</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.831542</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.602686</td>\n",
       "      <td>0.782553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>seresnext101_32x8d</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.952096</td>\n",
       "      <td>0.478333</td>\n",
       "      <td>0.504776</td>\n",
       "      <td>0.696192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>seresnext101_32x8d</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.944684</td>\n",
       "      <td>0.463333</td>\n",
       "      <td>0.469694</td>\n",
       "      <td>0.648664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>seresnext101_32x8d</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.894767</td>\n",
       "      <td>0.668333</td>\n",
       "      <td>0.424386</td>\n",
       "      <td>0.750599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>seresnext101_32x8d</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.910851</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.410433</td>\n",
       "      <td>0.739901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>seresnext101_32x8d</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.018297</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.505092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>seresnext101_32x8d</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.149403</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.302908</td>\n",
       "      <td>0.598857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name  partition optimizer  batch_size  lr_init      loss  \\\n",
       "351  seresnext101_32x8d  test-last  NovoGrad           4   0.0010  1.287907   \n",
       "350  seresnext101_32x8d       test  NovoGrad           4   0.0010  0.986254   \n",
       "332  seresnext101_32x8d       test     AdamW          32   0.0001  0.826894   \n",
       "333  seresnext101_32x8d  test-last     AdamW          32   0.0001  0.826894   \n",
       "339  seresnext101_32x8d  test-last       SGD           4   0.0010  0.901108   \n",
       "338  seresnext101_32x8d       test       SGD           4   0.0010  0.831542   \n",
       "342  seresnext101_32x8d  test-last      Adam           4   0.0010  0.952096   \n",
       "341  seresnext101_32x8d       test      Adam           4   0.0010  0.944684   \n",
       "348  seresnext101_32x8d  test-last  Adadelta           4   0.0010  0.894767   \n",
       "347  seresnext101_32x8d       test  Adadelta           4   0.0010  0.910851   \n",
       "344  seresnext101_32x8d       test     AdamW           4   0.0010  1.018297   \n",
       "345  seresnext101_32x8d  test-last     AdamW           4   0.0010  1.149403   \n",
       "\n",
       "     accuracy  balanced_accuracy       auc  \n",
       "351  0.728333           0.656595  0.807500  \n",
       "350  0.708333           0.628410  0.815344  \n",
       "332  0.608333           0.628355  0.816871  \n",
       "333  0.608333           0.628355  0.816871  \n",
       "339  0.646667           0.604739  0.779208  \n",
       "338  0.655000           0.602686  0.782553  \n",
       "342  0.478333           0.504776  0.696192  \n",
       "341  0.463333           0.469694  0.648664  \n",
       "348  0.668333           0.424386  0.750599  \n",
       "347  0.660000           0.410433  0.739901  \n",
       "344  0.655000           0.333333  0.505092  \n",
       "345  0.473333           0.302908  0.598857  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'seresnext101_32x8d'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# NovoGrad 4 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.361970</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>0.671086</td>\n",
       "      <td>0.855218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.537387</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.659444</td>\n",
       "      <td>0.842648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.392208</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.655171</td>\n",
       "      <td>0.847955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.966588</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.652311</td>\n",
       "      <td>0.812523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.006841</td>\n",
       "      <td>0.698333</td>\n",
       "      <td>0.643620</td>\n",
       "      <td>0.820805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.079386</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.640312</td>\n",
       "      <td>0.819196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.936757</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.795419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.432838</td>\n",
       "      <td>0.588333</td>\n",
       "      <td>0.631600</td>\n",
       "      <td>0.784579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.898821</td>\n",
       "      <td>0.576667</td>\n",
       "      <td>0.618262</td>\n",
       "      <td>0.804563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.920990</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.614841</td>\n",
       "      <td>0.787615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>SGDP</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.880584</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.607621</td>\n",
       "      <td>0.787534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3.017790</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.604769</td>\n",
       "      <td>0.808097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.899005</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.596005</td>\n",
       "      <td>0.801247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>SGDP</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.089473</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.569898</td>\n",
       "      <td>0.769822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.015906</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.505259</td>\n",
       "      <td>0.677627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.164459</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.486823</td>\n",
       "      <td>0.690663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Radam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.577896</td>\n",
       "      <td>0.331667</td>\n",
       "      <td>0.461236</td>\n",
       "      <td>0.713507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.093011</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.334747</td>\n",
       "      <td>0.482825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Adafactor</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.034339</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.588169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.049359</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.956048</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamP</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.021490</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.054260</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.511653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.060630</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.499064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.043860</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Lookahead_AdamP</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.081484</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.490260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Lookahead_AdamP</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.024329</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.539693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.035111</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.498103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Adafactor</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.043656</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.476593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.084668</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.091885</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.479968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamP</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.076936</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.489383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>test</td>\n",
       "      <td>Radam</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.057343</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.531780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name partition        optimizer  batch_size  lr_init      loss  \\\n",
       "25      vgg19      test              SGD          32   0.0010  1.361970   \n",
       "47      vgg19      test         NovoGrad          32   0.0010  1.537387   \n",
       "49      vgg19      test              SGD          32   0.0010  1.392208   \n",
       "61      vgg19      test            AdamW          32   0.0001  0.966588   \n",
       "55      vgg19      test         NovoGrad          32   0.0010  1.006841   \n",
       "1       vgg19      test              SGD          10   0.0010  1.079386   \n",
       "65      vgg19      test         NovoGrad          32   0.0001  0.936757   \n",
       "59      vgg19      test             Adam          32   0.0001  1.432838   \n",
       "53      vgg19      test         Adadelta          32   0.0010  0.898821   \n",
       "17      vgg19      test         Adadelta          10   0.0010  0.920990   \n",
       "15      vgg19      test             SGDP          10   0.0010  0.880584   \n",
       "23      vgg19      test         NovoGrad          10   0.0010  3.017790   \n",
       "57      vgg19      test              SGD          32   0.0001  0.899005   \n",
       "39      vgg19      test             SGDP          32   0.0010  1.089473   \n",
       "63      vgg19      test         Adadelta          32   0.0001  1.015906   \n",
       "41      vgg19      test         Adadelta          32   0.0010  1.164459   \n",
       "33      vgg19      test            Radam          32   0.0010  1.577896   \n",
       "51      vgg19      test             Adam          32   0.0010  1.093011   \n",
       "19      vgg19      test        Adafactor          10   0.0010  1.034339   \n",
       "5       vgg19      test            AdamW          10   0.0010  1.049359   \n",
       "21      vgg19      test          RMSprop          10   0.0010  0.956048   \n",
       "13      vgg19      test            AdamP          10   0.0010  1.021490   \n",
       "7       vgg19      test            Nadam          10   0.0010  1.054260   \n",
       "27      vgg19      test             Adam          32   0.0010  1.060630   \n",
       "3       vgg19      test             Adam          10   0.0010  1.043860   \n",
       "35      vgg19      test  Lookahead_AdamP          32   0.0010  1.081484   \n",
       "11      vgg19      test  Lookahead_AdamP          10   0.0010  1.024329   \n",
       "45      vgg19      test          RMSprop          32   0.0010  1.035111   \n",
       "43      vgg19      test        Adafactor          32   0.0010  1.043656   \n",
       "29      vgg19      test            AdamW          32   0.0010  1.084668   \n",
       "31      vgg19      test            Nadam          32   0.0010  1.091885   \n",
       "37      vgg19      test            AdamP          32   0.0010  1.076936   \n",
       "9       vgg19      test            Radam          10   0.0010  1.057343   \n",
       "\n",
       "    accuracy  balanced_accuracy       auc  \n",
       "25  0.743333           0.671086  0.855218  \n",
       "47  0.730000           0.659444  0.842648  \n",
       "49  0.730000           0.655171  0.847955  \n",
       "61  0.676667           0.652311  0.812523  \n",
       "55  0.698333           0.643620  0.820805  \n",
       "1   0.670000           0.640312  0.819196  \n",
       "65  0.593333           0.636728  0.795419  \n",
       "59  0.588333           0.631600  0.784579  \n",
       "53  0.576667           0.618262  0.804563  \n",
       "17  0.626667           0.614841  0.787615  \n",
       "15  0.640000           0.607621  0.787534  \n",
       "23  0.693333           0.604769  0.808097  \n",
       "57  0.625000           0.596005  0.801247  \n",
       "39  0.595000           0.569898  0.769822  \n",
       "63  0.553333           0.505259  0.677627  \n",
       "41  0.415000           0.486823  0.690663  \n",
       "33  0.331667           0.461236  0.713507  \n",
       "51  0.606667           0.334747  0.482825  \n",
       "19  0.655000           0.333333  0.588169  \n",
       "5   0.655000           0.333333  0.500000  \n",
       "21  0.655000           0.333333  0.500000  \n",
       "13  0.655000           0.333333  0.500000  \n",
       "7   0.655000           0.333333  0.511653  \n",
       "27  0.655000           0.333333  0.499064  \n",
       "3   0.655000           0.333333  0.500000  \n",
       "35  0.655000           0.333333  0.490260  \n",
       "11  0.655000           0.333333  0.539693  \n",
       "45  0.655000           0.333333  0.498103  \n",
       "43  0.655000           0.333333  0.476593  \n",
       "29  0.655000           0.333333  0.500000  \n",
       "31  0.655000           0.333333  0.479968  \n",
       "37  0.655000           0.333333  0.489383  \n",
       "9   0.655000           0.333333  0.531780  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'vgg19'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# SGD 32 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.833346</td>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.575077</td>\n",
       "      <td>0.752968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.817403</td>\n",
       "      <td>0.643333</td>\n",
       "      <td>0.574740</td>\n",
       "      <td>0.758306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.849228</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.572532</td>\n",
       "      <td>0.751172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.942252</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.571882</td>\n",
       "      <td>0.731310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.045685</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.551062</td>\n",
       "      <td>0.724793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.006243</td>\n",
       "      <td>0.481667</td>\n",
       "      <td>0.543653</td>\n",
       "      <td>0.686126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.841019</td>\n",
       "      <td>0.628333</td>\n",
       "      <td>0.543368</td>\n",
       "      <td>0.732005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.895365</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.532755</td>\n",
       "      <td>0.698185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.942553</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.525202</td>\n",
       "      <td>0.708508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.102822</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.520869</td>\n",
       "      <td>0.699128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.955861</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.519273</td>\n",
       "      <td>0.702559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.078662</td>\n",
       "      <td>0.401667</td>\n",
       "      <td>0.519180</td>\n",
       "      <td>0.711791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.041677</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.515920</td>\n",
       "      <td>0.677513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.879112</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.510450</td>\n",
       "      <td>0.719944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.019593</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.510393</td>\n",
       "      <td>0.686381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.957066</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.504991</td>\n",
       "      <td>0.686739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.212579</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.499767</td>\n",
       "      <td>0.685637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.090657</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.498995</td>\n",
       "      <td>0.698472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.068929</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.496910</td>\n",
       "      <td>0.692318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.040610</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.496616</td>\n",
       "      <td>0.684205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.085710</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.496414</td>\n",
       "      <td>0.675242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.072531</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.495492</td>\n",
       "      <td>0.678025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.109641</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.493339</td>\n",
       "      <td>0.682560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.224939</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.491418</td>\n",
       "      <td>0.690094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.126422</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.485694</td>\n",
       "      <td>0.672230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.104136</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.484370</td>\n",
       "      <td>0.665649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.986020</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.484241</td>\n",
       "      <td>0.670287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.005698</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.477219</td>\n",
       "      <td>0.654506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.978427</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.476038</td>\n",
       "      <td>0.668936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdaDelta</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.142870</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.473039</td>\n",
       "      <td>0.662973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.050432</td>\n",
       "      <td>0.461667</td>\n",
       "      <td>0.472576</td>\n",
       "      <td>0.666736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.137128</td>\n",
       "      <td>0.368333</td>\n",
       "      <td>0.468785</td>\n",
       "      <td>0.657711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.954106</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.468189</td>\n",
       "      <td>0.656646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.124965</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.465618</td>\n",
       "      <td>0.662374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.043636</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.465103</td>\n",
       "      <td>0.653574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.038879</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.462087</td>\n",
       "      <td>0.656689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.077258</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.461182</td>\n",
       "      <td>0.647225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.012862</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.460562</td>\n",
       "      <td>0.668060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.245351</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.459094</td>\n",
       "      <td>0.663361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.201922</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.458985</td>\n",
       "      <td>0.661902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>AdaDelta</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.122225</td>\n",
       "      <td>0.371667</td>\n",
       "      <td>0.454475</td>\n",
       "      <td>0.658448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.092785</td>\n",
       "      <td>0.353333</td>\n",
       "      <td>0.448292</td>\n",
       "      <td>0.629061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.404530</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.445543</td>\n",
       "      <td>0.647808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.098699</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.444044</td>\n",
       "      <td>0.627588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.275978</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.443925</td>\n",
       "      <td>0.645118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.075214</td>\n",
       "      <td>0.378333</td>\n",
       "      <td>0.441880</td>\n",
       "      <td>0.640910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdaDelta</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.093187</td>\n",
       "      <td>0.361667</td>\n",
       "      <td>0.433710</td>\n",
       "      <td>0.611304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.023185</td>\n",
       "      <td>0.468333</td>\n",
       "      <td>0.410252</td>\n",
       "      <td>0.614417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.916345</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.394676</td>\n",
       "      <td>0.660170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>senet154</td>\n",
       "      <td>test</td>\n",
       "      <td>AdaDelta</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.079999</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.351189</td>\n",
       "      <td>0.513683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name  partition optimizer  batch_size  lr_init      loss  accuracy  \\\n",
       "402   senet154  test-last      Adam           4   0.0010  0.833346  0.631667   \n",
       "405   senet154  test-last     AdamW           4   0.0010  0.817403  0.643333   \n",
       "401   senet154       test      Adam           4   0.0010  0.849228  0.626667   \n",
       "563   senet154  test-last     AdamW           8   0.0010  0.942252  0.540000   \n",
       "411   senet154  test-last  NovoGrad           4   0.0010  1.045685  0.583333   \n",
       "425   senet154       test      Adam          25   0.0010  1.006243  0.481667   \n",
       "622   senet154       test     AdamW           8   0.0001  0.841019  0.628333   \n",
       "404   senet154       test     AdamW           4   0.0010  0.895365  0.635000   \n",
       "399   senet154  test-last       SGD           4   0.0010  0.942553  0.560000   \n",
       "426   senet154  test-last      Adam          25   0.0010  1.102822  0.406667   \n",
       "571   senet154       test  NovoGrad           8   0.0010  0.955861  0.650000   \n",
       "566   senet154  test-last     AdamW          16   0.0010  1.078662  0.401667   \n",
       "635   senet154  test-last  NovoGrad           8   0.0001  1.041677  0.480000   \n",
       "410   senet154       test  NovoGrad           4   0.0010  0.879112  0.586667   \n",
       "417   senet154  test-last  NovoGrad          32   0.0010  1.019593  0.556667   \n",
       "398   senet154       test       SGD           4   0.0010  0.957066  0.591667   \n",
       "623   senet154  test-last     AdamW           8   0.0001  1.212579  0.566667   \n",
       "414   senet154  test-last       SGD          32   0.0010  1.090657  0.436667   \n",
       "413   senet154       test       SGD          32   0.0010  1.068929  0.453333   \n",
       "434   senet154       test      Adam          25   0.0001  1.040610  0.503333   \n",
       "574   senet154       test  NovoGrad          16   0.0010  1.085710  0.550000   \n",
       "626   senet154  test-last     AdamW          16   0.0001  1.072531  0.616667   \n",
       "429   senet154  test-last     AdamW          25   0.0010  1.109641  0.373333   \n",
       "572   senet154  test-last  NovoGrad           8   0.0010  1.224939  0.630000   \n",
       "437   senet154       test     AdamW          25   0.0001  1.126422  0.633333   \n",
       "420   senet154  test-last       SGD          32   0.0001  1.104136  0.391667   \n",
       "634   senet154       test  NovoGrad           8   0.0001  0.986020  0.523333   \n",
       "562   senet154       test     AdamW           8   0.0010  1.005698  0.441667   \n",
       "408   senet154  test-last  Adadelta           4   0.0010  0.978427  0.510000   \n",
       "432   senet154  test-last  AdaDelta          25   0.0010  1.142870  0.373333   \n",
       "569   senet154  test-last  Adadelta           8   0.0010  1.050432  0.461667   \n",
       "422   senet154       test  NovoGrad          32   0.0001  1.137128  0.368333   \n",
       "407   senet154       test  Adadelta           4   0.0010  0.954106  0.535000   \n",
       "423   senet154  test-last  NovoGrad          32   0.0001  1.124965  0.373333   \n",
       "568   senet154       test  Adadelta           8   0.0010  1.043636  0.470000   \n",
       "419   senet154       test       SGD          32   0.0001  1.038879  0.446667   \n",
       "629   senet154  test-last  Adadelta           8   0.0001  1.077258  0.400000   \n",
       "625   senet154       test     AdamW          16   0.0001  1.012862  0.513333   \n",
       "438   senet154  test-last     AdamW          25   0.0001  1.245351  0.640000   \n",
       "435   senet154  test-last      Adam          25   0.0001  1.201922  0.608333   \n",
       "431   senet154       test  AdaDelta          25   0.0010  1.122225  0.371667   \n",
       "631   senet154       test  Adadelta          16   0.0001  1.092785  0.353333   \n",
       "575   senet154  test-last  NovoGrad          16   0.0010  1.404530  0.608333   \n",
       "632   senet154  test-last  Adadelta          16   0.0001  1.098699  0.346667   \n",
       "416   senet154       test  NovoGrad          32   0.0010  1.275978  0.416667   \n",
       "628   senet154       test  Adadelta           8   0.0001  1.075214  0.378333   \n",
       "441   senet154  test-last  AdaDelta          25   0.0001  1.093187  0.361667   \n",
       "428   senet154       test     AdamW          25   0.0010  1.023185  0.468333   \n",
       "565   senet154       test     AdamW          16   0.0010  0.916345  0.556667   \n",
       "440   senet154       test  AdaDelta          25   0.0001  1.079999  0.416667   \n",
       "\n",
       "     balanced_accuracy       auc  \n",
       "402           0.575077  0.752968  \n",
       "405           0.574740  0.758306  \n",
       "401           0.572532  0.751172  \n",
       "563           0.571882  0.731310  \n",
       "411           0.551062  0.724793  \n",
       "425           0.543653  0.686126  \n",
       "622           0.543368  0.732005  \n",
       "404           0.532755  0.698185  \n",
       "399           0.525202  0.708508  \n",
       "426           0.520869  0.699128  \n",
       "571           0.519273  0.702559  \n",
       "566           0.519180  0.711791  \n",
       "635           0.515920  0.677513  \n",
       "410           0.510450  0.719944  \n",
       "417           0.510393  0.686381  \n",
       "398           0.504991  0.686739  \n",
       "623           0.499767  0.685637  \n",
       "414           0.498995  0.698472  \n",
       "413           0.496910  0.692318  \n",
       "434           0.496616  0.684205  \n",
       "574           0.496414  0.675242  \n",
       "626           0.495492  0.678025  \n",
       "429           0.493339  0.682560  \n",
       "572           0.491418  0.690094  \n",
       "437           0.485694  0.672230  \n",
       "420           0.484370  0.665649  \n",
       "634           0.484241  0.670287  \n",
       "562           0.477219  0.654506  \n",
       "408           0.476038  0.668936  \n",
       "432           0.473039  0.662973  \n",
       "569           0.472576  0.666736  \n",
       "422           0.468785  0.657711  \n",
       "407           0.468189  0.656646  \n",
       "423           0.465618  0.662374  \n",
       "568           0.465103  0.653574  \n",
       "419           0.462087  0.656689  \n",
       "629           0.461182  0.647225  \n",
       "625           0.460562  0.668060  \n",
       "438           0.459094  0.663361  \n",
       "435           0.458985  0.661902  \n",
       "431           0.454475  0.658448  \n",
       "631           0.448292  0.629061  \n",
       "575           0.445543  0.647808  \n",
       "632           0.444044  0.627588  \n",
       "416           0.443925  0.645118  \n",
       "628           0.441880  0.640910  \n",
       "441           0.433710  0.611304  \n",
       "428           0.410252  0.614417  \n",
       "565           0.394676  0.660170  \n",
       "440           0.351189  0.513683  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'senet154'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# Adam 4 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.961343</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>0.740693</td>\n",
       "      <td>0.868702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.870377</td>\n",
       "      <td>0.781667</td>\n",
       "      <td>0.737448</td>\n",
       "      <td>0.886487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.119759</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.735371</td>\n",
       "      <td>0.870636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.848061</td>\n",
       "      <td>0.781667</td>\n",
       "      <td>0.727735</td>\n",
       "      <td>0.870686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.137538</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.727607</td>\n",
       "      <td>0.874266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>0.368333</td>\n",
       "      <td>0.452739</td>\n",
       "      <td>0.707395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.085161</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.452422</td>\n",
       "      <td>0.708323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.136365</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.450984</td>\n",
       "      <td>0.668126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.234015</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.441691</td>\n",
       "      <td>0.707006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.024693</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.406050</td>\n",
       "      <td>0.587713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name  partition optimizer  batch_size  lr_init      loss  \\\n",
       "99   resnext101_32x8d  test-last      Adam          32   0.0001  0.961343   \n",
       "650  resnext101_32x8d  test-last     AdamW          16   0.0001  0.870377   \n",
       "605  resnext101_32x8d  test-last  NovoGrad          16   0.0010  1.119759   \n",
       "80   resnext101_32x8d       test       SGD          32   0.0010  0.848061   \n",
       "646  resnext101_32x8d       test     AdamW           8   0.0001  1.137538   \n",
       "..                ...        ...       ...         ...      ...       ...   \n",
       "105  resnext101_32x8d  test-last  Adadelta          32   0.0001  1.090000   \n",
       "104  resnext101_32x8d       test  Adadelta          32   0.0001  1.085161   \n",
       "584  resnext101_32x8d  test-last     AdamW           8   0.0010  1.136365   \n",
       "655  resnext101_32x8d       test  Adadelta          16   0.0001  1.234015   \n",
       "580  resnext101_32x8d       test      Adam          16   0.0010  1.024693   \n",
       "\n",
       "     accuracy  balanced_accuracy       auc  \n",
       "99   0.761667           0.740693  0.868702  \n",
       "650  0.781667           0.737448  0.886487  \n",
       "605  0.741667           0.735371  0.870636  \n",
       "80   0.781667           0.727735  0.870686  \n",
       "646  0.750000           0.727607  0.874266  \n",
       "..        ...                ...       ...  \n",
       "105  0.368333           0.452739  0.707395  \n",
       "104  0.375000           0.452422  0.708323  \n",
       "584  0.380000           0.450984  0.668126  \n",
       "655  0.253333           0.441691  0.707006  \n",
       "580  0.450000           0.406050  0.587713  \n",
       "\n",
       "[70 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'resnext101_32x8d'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# Adam\t32\t0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr_init</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.826203</td>\n",
       "      <td>0.728333</td>\n",
       "      <td>0.714289</td>\n",
       "      <td>0.867523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.141925</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.713777</td>\n",
       "      <td>0.865586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.805610</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.711568</td>\n",
       "      <td>0.873314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test-last</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.827042</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.710182</td>\n",
       "      <td>0.860994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test</td>\n",
       "      <td>NovoGrad</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.954075</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.707412</td>\n",
       "      <td>0.858143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test-last</td>\n",
       "      <td>SGD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.958012</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.691586</td>\n",
       "      <td>0.871155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.796553</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.638688</td>\n",
       "      <td>0.819445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.808587</td>\n",
       "      <td>0.636667</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.823371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.801701</td>\n",
       "      <td>0.648333</td>\n",
       "      <td>0.630141</td>\n",
       "      <td>0.817246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.859272</td>\n",
       "      <td>0.598333</td>\n",
       "      <td>0.618973</td>\n",
       "      <td>0.819269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.246427</td>\n",
       "      <td>0.623333</td>\n",
       "      <td>0.376329</td>\n",
       "      <td>0.609690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.622676</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.348487</td>\n",
       "      <td>0.501655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5.503844</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.340989</td>\n",
       "      <td>0.504001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5.634429</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.470064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test-last</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.414471</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.324808</td>\n",
       "      <td>0.500816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>41.994494</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.300146</td>\n",
       "      <td>0.500259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>143.676944</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.277071</td>\n",
       "      <td>0.460324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>test-last</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.199907</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.273178</td>\n",
       "      <td>0.545657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model_name  partition optimizer  batch_size  lr_init        loss  \\\n",
       "545  pnasnet5large       test  NovoGrad           4    0.001    1.826203   \n",
       "533  pnasnet5large       test       SGD           4    0.001    1.141925   \n",
       "546  pnasnet5large  test-last  NovoGrad           4    0.001    1.805610   \n",
       "558  pnasnet5large  test-last  NovoGrad           4    0.001    1.827042   \n",
       "557  pnasnet5large       test  NovoGrad           4    0.001    1.954075   \n",
       "534  pnasnet5large  test-last       SGD           4    0.001    0.958012   \n",
       "542  pnasnet5large       test  Adadelta           4    0.001    0.796553   \n",
       "555  pnasnet5large  test-last  Adadelta           4    0.001    0.808587   \n",
       "543  pnasnet5large  test-last  Adadelta           4    0.001    0.801701   \n",
       "554  pnasnet5large       test  Adadelta           4    0.001    0.859272   \n",
       "548  pnasnet5large       test      Adam           4    0.001    2.246427   \n",
       "551  pnasnet5large       test     AdamW           4    0.001    1.622676   \n",
       "536  pnasnet5large       test      Adam           4    0.001    5.503844   \n",
       "549  pnasnet5large  test-last      Adam           4    0.001    5.634429   \n",
       "537  pnasnet5large  test-last      Adam           4    0.001    1.414471   \n",
       "539  pnasnet5large       test     AdamW           4    0.001   41.994494   \n",
       "540  pnasnet5large  test-last     AdamW           4    0.001  143.676944   \n",
       "552  pnasnet5large  test-last     AdamW           4    0.001    1.199907   \n",
       "\n",
       "     accuracy  balanced_accuracy       auc  \n",
       "545  0.728333           0.714289  0.867523  \n",
       "533  0.720000           0.713777  0.865586  \n",
       "546  0.758333           0.711568  0.873314  \n",
       "558  0.750000           0.710182  0.860994  \n",
       "557  0.733333           0.707412  0.858143  \n",
       "534  0.756667           0.691586  0.871155  \n",
       "542  0.653333           0.638688  0.819445  \n",
       "555  0.636667           0.630769  0.823371  \n",
       "543  0.648333           0.630141  0.817246  \n",
       "554  0.598333           0.618973  0.819269  \n",
       "548  0.623333           0.376329  0.609690  \n",
       "551  0.595000           0.348487  0.501655  \n",
       "536  0.615000           0.340989  0.504001  \n",
       "549  0.655000           0.333333  0.470064  \n",
       "537  0.595000           0.324808  0.500816  \n",
       "539  0.558333           0.300146  0.500259  \n",
       "540  0.493333           0.277071  0.460324  \n",
       "552  0.525000           0.273178  0.545657  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[df_aux['model_name'] == 'pnasnet5large'].sort_values(by='balanced_accuracy', ascending=False)\n",
    "# NovoGrad\t4\t0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fd7eb7b2e50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['model_name'], as_index=False)['optimizer']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfd3d9b3a247477dc4ddd471980b0e91a7ad08d342b57fc04d563ff096025d07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
