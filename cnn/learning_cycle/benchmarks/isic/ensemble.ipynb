{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Calculate ensemble average for all experiments"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import numpy as np\n",
            "from raug.metrics import Metrics, accuracy\n",
            "from raug.utils.loader import get_labels_frequency\n",
            "import pandas as pd\n",
            "\n",
            "# Especificar o caminho para a pasta \"best_results\"\n",
            "folder_path = \"best_results\"\n",
            "_csv_path_test = \"/home/a52550/Desktop/datasets/ISIC2017/test/ISIC-2017_Test_v2_Part3_GroundTruth.csv\"\n",
            "true_labels = pd.read_csv(_csv_path_test).sort_values(by=['image_id'])['category']\n",
            "\n",
            "# Inicializar as variáveis para armazenar as previsões dos modelos\n",
            "ensemble_preds_best = None\n",
            "ensemble_preds_last = None\n",
            "num_models = 0\n",
            "ser_lab_freq = get_labels_frequency(_csv_path_test, \"category\", \"image_id\")\n",
            "_labels_name = ser_lab_freq.index.values #np.reshape(ser_lab_freq.index.values, (ser_lab_freq.index.values.shape[0], 1))\n",
            "\n",
            "df_best = pd.DataFrame()\n",
            "df_last = pd.DataFrame()\n",
            "\n",
            "# Percorrer as pastas de cada experimento\n",
            "for experiment_folder in os.listdir(folder_path):\n",
            "\n",
            "    if \".csv\" in experiment_folder or \".txt\" in experiment_folder:\n",
            "        continue\n",
            "\n",
            "    # if \"ensemble_average\" in os.listdir(os.path.join(folder_path,experiment_folder)):\n",
            "    #     continue\n",
            "\n",
            "    print(\"Experimento: \", experiment_folder)\n",
            "\n",
            "    _metric_options_best = {\n",
            "        'save_all_path': os.path.join(folder_path, experiment_folder, 'ensemble_average/best'),\n",
            "        'pred_name_scores': 'predictions.csv',\n",
            "    }\n",
            "    _metric_options_last = {\n",
            "        'save_all_path': os.path.join(folder_path, experiment_folder, 'ensemble_average/last'),\n",
            "        'pred_name_scores': 'predictions.csv',\n",
            "    }\n",
            "\n",
            "\n",
            "    experiment_path = os.path.join(folder_path, experiment_folder)\n",
            "    metrics_best = Metrics ([\"accuracy\", \"topk_accuracy\", \"balanced_accuracy\", \"conf_matrix\" \"plot_conf_matrix\", \"precision_recall_report\", \"auc_and_roc_curve\", \"auc\"] , _labels_name, _metric_options_best)\n",
            "    metrics_last = Metrics ([\"accuracy\", \"topk_accuracy\", \"balanced_accuracy\", \"conf_matrix\" \"plot_conf_matrix\", \"precision_recall_report\", \"auc_and_roc_curve\", \"auc\"] , _labels_name, _metric_options_last)\n",
            "\n",
            "    ensemble_preds_best = None\n",
            "    ensemble_preds_last = None\n",
            "\n",
            "    model_folders = os.listdir(experiment_path)\n",
            "\n",
            "    # Check if substring \"senet154\" is present in model_folders\n",
            "    if any(\"senet154\" in s for s in model_folders):\n",
            "        continue\n",
            "\n",
            "    \n",
            "    # Cria path para o experimento atual\n",
            "    if 'ensemble_average' in model_folders:\n",
            "        model_folders.remove('ensemble_average')\n",
            "    else:\n",
            "        os.mkdir(os.path.join(folder_path, experiment_folder, 'ensemble_average'))\n",
            "        os.mkdir(os.path.join(_metric_options_best['save_all_path']))\n",
            "        os.mkdir(os.path.join(_metric_options_last['save_all_path']))\n",
            "\n",
            "    if 'ensemble_3_best_average' in model_folders:\n",
            "        model_folders.remove('ensemble_3_best_average')\n",
            "    \n",
            "    if 'ensemble_votation' in model_folders:\n",
            "        model_folders.remove('ensemble_votation')\n",
            "    \n",
            "    if 'DAandPPlatex.txt' in model_folders:\n",
            "        model_folders.remove('DAandPPlatex.txt')\n",
            "\n",
            "    model_folders = [x for x in model_folders if \".csv\" not in x]\n",
            "\n",
            "    try:\n",
            "\n",
            "        # Percorrer as pastas de cada modelo\n",
            "        for model_folder in model_folders:\n",
            "\n",
            "            model_path = os.path.join(experiment_path, model_folder)\n",
            "\n",
            "            # Carregar as previsões do modelo atual\n",
            "            model_preds_path_best = os.path.join(model_path, \"test_pred_best/predictions.csv\")\n",
            "            model_preds_path_last = os.path.join(model_path, \"test_pred_last/predictions.csv\")\n",
            "\n",
            "            model_preds_best = pd.read_csv(model_preds_path_best).sort_values(by=['image'])\n",
            "            model_preds_last = pd.read_csv(model_preds_path_last).sort_values(by=['image'])\n",
            "\n",
            "            images_id = model_preds_best[['image']]\n",
            "            model_preds_best = model_preds_best[['0','1','2']]\n",
            "            model_preds_last = model_preds_last[['0','1','2']]\n",
            "\n",
            "            # Adicionar as previsões do modelo atual ao ensemble\n",
            "            if ensemble_preds_best is None:\n",
            "                ensemble_preds_best = model_preds_best\n",
            "            else:\n",
            "                ensemble_preds_best += model_preds_best\n",
            "\n",
            "            if ensemble_preds_last is None:\n",
            "                ensemble_preds_last = model_preds_last\n",
            "            else:\n",
            "                ensemble_preds_last += model_preds_last\n",
            "\n",
            "            num_models += 1\n",
            "\n",
            "        # Calcular a média das previsões dos modelos\n",
            "        ensemble_preds_best /= num_models\n",
            "        ensemble_preds_last /= num_models\n",
            "\n",
            "        metrics_best.update_scores(true_labels, ensemble_preds_best.to_numpy(), images_id.to_numpy())\n",
            "        metrics_last.update_scores(true_labels, ensemble_preds_last.to_numpy(), images_id.to_numpy())\n",
            "\n",
            "        metrics_best.compute_metrics()\n",
            "        metrics_last.compute_metrics()\n",
            "\n",
            "        metrics_best.save_scores()\n",
            "        metrics_last.save_scores()\n",
            "\n",
            "        for auc_metric in metrics_best.metrics_values['auc_and_roc_curve'][0]:\n",
            "            metrics_best.metrics_values[\"auc_\" + str(auc_metric)] = metrics_best.metrics_values['auc_and_roc_curve'][0][auc_metric]\n",
            "            metrics_last.metrics_values[\"auc_\" + str(auc_metric)] = metrics_last.metrics_values['auc_and_roc_curve'][0][auc_metric]\n",
            "\n",
            "        folder_name = {'folder_name': experiment_folder}\n",
            "        dict_best = {**folder_name, **metrics_best.metrics_values}\n",
            "        dict_last = {**folder_name, **metrics_last.metrics_values}\n",
            "\n",
            "        del dict_best['auc_and_roc_curve']\n",
            "        del dict_best['precision_recall_report']\n",
            "\n",
            "        del dict_last['auc_and_roc_curve']\n",
            "        del dict_last['precision_recall_report']\n",
            "\n",
            "        df_best = df_best.append(pd.DataFrame(dict_best, columns=dict_best.keys(), index=[0]), ignore_index=True)\n",
            "        df_last = df_last.append(pd.DataFrame(dict_last, columns=dict_last.keys(), index=[0]), ignore_index=True)\n",
            "\n",
            "    except Exception as e:\n",
            "        print(\"Erro no experimento \", experiment_folder)\n",
            "        print(e)\n",
            "\n",
            "# read csv file\n",
            "# df = pd.read_csv(os.path.join(folder_path, 'ensemble_average_best.csv'))\n",
            "# append df_best to df\n",
            "# df = df.append(df_best, ignore_index=True)\n",
            "df_best.to_csv(os.path.join(folder_path, 'ensemble_average_best.csv'), index=False)\n",
            "# read csv file\n",
            "# df2 = pd.read_csv(os.path.join(folder_path, 'ensemble_average_last.csv'))\n",
            "# append df_best to df\n",
            "# df2 = df2.append(df_last, ignore_index=True)\n",
            "df_last.to_csv(os.path.join(folder_path, 'ensemble_average_last.csv'), index=False)\n",
            "\n",
            "# Avaliar a precisão do modelo de ensemble\n",
            "# true_classes_path = os.path.join(folder_path, \"true_classes.csv\")\n",
            "# true_classes = np.loadtxt(_csv_path_test, delimiter=\",\", skiprows=1)\n",
            "\n",
            "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
            "\n",
            "# accuracy = accuracy_score(true_classes, ensemble_classes)\n",
            "# precision = precision_score(true_classes, ensemble_classes, average=\"macro\")\n",
            "# recall = recall_score(true_classes, ensemble_classes, average=\"macro\")\n",
            "# f1 = f1_score(true_classes, ensemble_classes, average=\"macro\")\n",
            "\n",
            "# # Imprimir as métricas de avaliação\n",
            "# print(f\"Acurácia: {accuracy:.3f}\")\n",
            "# print(f\"Precisão: {precision:.3f}\")\n",
            "# print(f\"Recall: {recall:.3f}\")\n",
            "# print(f\"F1-score: {f1:.3f}\")\n"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Calculate ensemble average of the best 3 models for all experiments"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import numpy as np\n",
            "from raug.metrics import Metrics, accuracy\n",
            "from raug.utils.loader import get_labels_frequency\n",
            "import pandas as pd\n",
            "from raug.utils import classification_metrics as cmet\n",
            "\n",
            "# Especificar o caminho para a pasta \"best_results\"\n",
            "folder_path = \"best_results\"\n",
            "_csv_path_test = \"/home/a52550/Desktop/datasets/ISIC2017/test/ISIC-2017_Test_v2_Part3_GroundTruth.csv\"\n",
            "true_labels = pd.read_csv(_csv_path_test).sort_values(by=['image_id'])['category']\n",
            "\n",
            "# Inicializar as variáveis para armazenar as previsões dos modelos\n",
            "ensemble_preds_best = None\n",
            "ensemble_preds_last = None\n",
            "num_models = 0\n",
            "ser_lab_freq = get_labels_frequency(_csv_path_test, \"category\", \"image_id\")\n",
            "_labels_name = ser_lab_freq.index.values #np.reshape(ser_lab_freq.index.values, (ser_lab_freq.index.values.shape[0], 1))\n",
            "\n",
            "df_best = pd.DataFrame()\n",
            "df_last = pd.DataFrame()\n",
            "\n",
            "# Percorrer as pastas de cada experimento\n",
            "for experiment_folder in os.listdir(folder_path):\n",
            "\n",
            "    try:\n",
            "        if \".csv\" in experiment_folder or \".txt\" in experiment_folder:\n",
            "            continue\n",
            "\n",
            "        # if \"ensemble_3_best_average\" in os.listdir(os.path.join(folder_path,experiment_folder)):\n",
            "        #     continue\n",
            "\n",
            "        options = {\n",
            "            'save_all_path': os.path.join(folder_path, experiment_folder, 'ensemble_3_best_average/best'),\n",
            "            'pred_name_scores': 'predictions.csv',\n",
            "        }\n",
            "\n",
            "\n",
            "        experiment_path = os.path.join(folder_path, experiment_folder)\n",
            "\n",
            "        ensemble_preds_best = None\n",
            "\n",
            "        model_folders = os.listdir(experiment_path)\n",
            "\n",
            "        model_folders = [x for x in model_folders if \".csv\" not in x]\n",
            "\n",
            "        # Check if substring \"senet154\" is present in model_folders\n",
            "        if any(\"senet154\" in s for s in model_folders):\n",
            "            print(\"Experimento \", experiment_folder, \" não será avaliado\")\n",
            "            continue\n",
            "\n",
            "        print(\"Experimento: \", experiment_folder)\n",
            "\n",
            "        \n",
            "        # Cria path para o experimento atual\n",
            "        if 'ensemble_average' in model_folders:\n",
            "            model_folders.remove('ensemble_average')\n",
            "        if 'ensemble_votation' in model_folders:\n",
            "            model_folders.remove('ensemble_votation')\n",
            "        if 'ensemble_3_best_average' in model_folders:\n",
            "            model_folders.remove('ensemble_3_best_average')\n",
            "        else:\n",
            "            os.mkdir(os.path.join(folder_path, experiment_folder, 'ensemble_3_best_average'))\n",
            "            os.mkdir(os.path.join(folder_path, experiment_folder, 'ensemble_3_best_average/best'))\n",
            "\n",
            "        if 'DAandPPlatex.txt' in model_folders:\n",
            "            model_folders.remove('DAandPPlatex.txt')\n",
            "\n",
            "        best_balanced_accuracy = 0\n",
            "        current_balanced_acuracy = 0\n",
            "        best_metric_ensemble = None\n",
            "\n",
            "        # Percorrer as pastas de cada modelo\n",
            "        for i1 in range(len(model_folders)-1):\n",
            "            for i2 in range(i1+1, len(model_folders)-1):\n",
            "                for i3 in range(i2+1, len(model_folders)-1):\n",
            "                    ensemble_folders = [model_folders[i1], model_folders[i2], model_folders[i3]]\n",
            "\n",
            "                    for model_folder in ensemble_folders:\n",
            "\n",
            "                        model_path = os.path.join(experiment_path, model_folder)\n",
            "\n",
            "                        # Carregar as previsões do modelo atual\n",
            "                        model_preds_path_best = os.path.join(model_path, \"test_pred_best/predictions.csv\")\n",
            "\n",
            "                        model_preds_best = pd.read_csv(model_preds_path_best).sort_values(by=['image'])\n",
            "\n",
            "                        images_id = model_preds_best[['image']]\n",
            "                        model_preds_best = model_preds_best[['0','1','2']]\n",
            "\n",
            "                        # Adicionar as previsões do modelo atual ao ensemble\n",
            "                        if ensemble_preds_best is None:\n",
            "                            ensemble_preds_best = model_preds_best\n",
            "                        else:\n",
            "                            ensemble_preds_best += model_preds_best\n",
            "\n",
            "                        num_models += 1\n",
            "\n",
            "                    # Calcular a média das previsões dos modelos\n",
            "                    ensemble_preds_best /= num_models\n",
            "                    \n",
            "                    # Calcular a balanced accuracy\n",
            "                    current_balanced_acuracy = cmet.balanced_accuracy(true_labels, ensemble_preds_best.to_numpy())\n",
            "\n",
            "\n",
            "                    if current_balanced_acuracy > best_balanced_accuracy:\n",
            "                        best_balanced_accuracy = current_balanced_acuracy\n",
            "\n",
            "                        best_metric_ensemble = Metrics ([\"accuracy\", \"topk_accuracy\", \"balanced_accuracy\", \"conf_matrix\" \"plot_conf_matrix\", \"precision_recall_report\", \"auc_and_roc_curve\", \"auc\"], _labels_name, options)\n",
            "                        best_metric_ensemble.update_scores(true_labels.to_numpy(), ensemble_preds_best.to_numpy(), images_id.to_numpy())\n",
            "\n",
            "                        best_experiment = experiment_folder\n",
            "\n",
            "                        ensemble_data = {\n",
            "                            'folder_name': experiment_folder,\n",
            "                            'ensemble_3_best': ensemble_folders[0].split('fold')[0] + \"_\" + ensemble_folders[1].split('fold')[0] + \"_\" + ensemble_folders[2].split('fold')[0]\n",
            "                        }\n",
            "                        \n",
            "\n",
            "                    ensemble_preds_best = None\n",
            "\n",
            "        best_metric_ensemble.compute_metrics()\n",
            "        best_metric_ensemble.save_scores()\n",
            "\n",
            "        for auc_metric in best_metric_ensemble.metrics_values['auc_and_roc_curve'][0]:\n",
            "            best_metric_ensemble.metrics_values[\"auc_\" + str(auc_metric)] = best_metric_ensemble.metrics_values['auc_and_roc_curve'][0][auc_metric]\n",
            "        \n",
            "        dict_best = {**ensemble_data, **best_metric_ensemble.metrics_values}\n",
            "\n",
            "        del dict_best['auc_and_roc_curve']\n",
            "        del dict_best['precision_recall_report']\n",
            "        # del dict_best['conf_matrix']\n",
            "        \n",
            "        df_best = df_best.append(pd.DataFrame(dict_best, columns=dict_best.keys(), index=[0]), ignore_index=True)\n",
            "    except Exception as e:\n",
            "        print('Error: ', e)\n",
            "        continue\n",
            "\n",
            "# read csv file\n",
            "# df = pd.read_csv(os.path.join(folder_path, 'ensemble_3_best_average_best.csv'))\n",
            "# # append df_best to df\n",
            "# df = df.append(df_best, ignore_index=True)\n",
            "df_best.to_csv(os.path.join(folder_path, 'ensemble_3_best_average_best.csv'), index=False)\n"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Calculate ensemble by voting for all experiments"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import numpy as np\n",
            "from raug.metrics import Metrics, accuracy\n",
            "from raug.utils.loader import get_labels_frequency\n",
            "import pandas as pd\n",
            "\n",
            "# Especificar o caminho para a pasta \"best_results\"\n",
            "folder_path = \"best_results\"\n",
            "_csv_path_test = \"/home/a52550/Desktop/datasets/ISIC2017/test/ISIC-2017_Test_v2_Part3_GroundTruth.csv\"\n",
            "true_labels = pd.read_csv(_csv_path_test).sort_values(by=['image_id'])['category']\n",
            "\n",
            "# Inicializar as variáveis para armazenar as previsões dos modelos\n",
            "ensemble_preds_best = None\n",
            "ensemble_preds_last = None\n",
            "num_models = 0\n",
            "ser_lab_freq = get_labels_frequency(_csv_path_test, \"category\", \"image_id\")\n",
            "_labels_name = ser_lab_freq.index.values #np.reshape(ser_lab_freq.index.values, (ser_lab_freq.index.values.shape[0], 1))\n",
            "\n",
            "df_best = pd.DataFrame()\n",
            "df_last = pd.DataFrame()\n",
            "\n",
            "# Percorrer as pastas de cada experimento\n",
            "for experiment_folder in os.listdir(folder_path):\n",
            "\n",
            "    if \".csv\" in experiment_folder or \".txt\" in experiment_folder:\n",
            "        continue\n",
            "    \n",
            "    # if \"ensemble_votation\" in os.listdir(os.path.join(folder_path,experiment_folder)):\n",
            "    #     continue\n",
            "\n",
            "    print(\"Experimento: \", experiment_folder)\n",
            "\n",
            "    _metric_options_best = {\n",
            "        'save_all_path': os.path.join(folder_path, experiment_folder, 'ensemble_votation/best'),\n",
            "        'pred_name_scores': 'predictions.csv',\n",
            "    }\n",
            "    _metric_options_last = {\n",
            "        'save_all_path': os.path.join(folder_path, experiment_folder, 'ensemble_votation/last'),\n",
            "        'pred_name_scores': 'predictions.csv',\n",
            "    }\n",
            "\n",
            "\n",
            "    experiment_path = os.path.join(folder_path, experiment_folder)\n",
            "    metrics_best = Metrics ([\"accuracy\", \"topk_accuracy\", \"balanced_accuracy\", \"conf_matrix\" \"plot_conf_matrix\", \"precision_recall_report\", \"auc_and_roc_curve\", \"auc\"] , _labels_name, _metric_options_best)\n",
            "    metrics_last = Metrics ([\"accuracy\", \"topk_accuracy\", \"balanced_accuracy\", \"conf_matrix\" \"plot_conf_matrix\", \"precision_recall_report\", \"auc_and_roc_curve\", \"auc\"] , _labels_name, _metric_options_last)\n",
            "\n",
            "    ensemble_preds_best = None\n",
            "    ensemble_preds_last = None\n",
            "\n",
            "    model_folders = os.listdir(experiment_path)\n",
            "    \n",
            "    models_folders = [x for x in model_folders if \".csv\" not in x]\n",
            "\n",
            "    # Check if substring \"senet154\" is present in model_folders\n",
            "    if any(\"senet154\" in s for s in model_folders):\n",
            "        continue\n",
            "\n",
            "    \n",
            "    # Cria path para o experimento atual\n",
            "    if 'ensemble_votation' in model_folders:\n",
            "        model_folders.remove('ensemble_votation')\n",
            "    else:\n",
            "        os.mkdir(os.path.join(folder_path, experiment_folder, 'ensemble_votation'))\n",
            "        os.mkdir(os.path.join(_metric_options_best['save_all_path']))\n",
            "        os.mkdir(os.path.join(_metric_options_last['save_all_path']))\n",
            "\n",
            "    if 'ensemble_3_best_average' in model_folders:\n",
            "        model_folders.remove('ensemble_3_best_average')\n",
            "    if 'ensemble_average' in model_folders:\n",
            "        model_folders.remove('ensemble_average')\n",
            "    if 'DAandPPlatex.txt' in model_folders:\n",
            "        model_folders.remove('DAandPPlatex.txt')\n",
            "\n",
            "    model_folders = [x for x in model_folders if \".csv\" not in x]\n",
            "\n",
            "    try:\n",
            "\n",
            "        # Percorrer as pastas de cada modelo\n",
            "        for model_folder in model_folders:\n",
            "\n",
            "            model_path = os.path.join(experiment_path, model_folder)\n",
            "\n",
            "            # Carregar as previsões do modelo atual\n",
            "            model_preds_path_best = os.path.join(model_path, \"test_pred_best/predictions.csv\")\n",
            "            model_preds_path_last = os.path.join(model_path, \"test_pred_last/predictions.csv\")\n",
            "\n",
            "            model_preds_best = pd.read_csv(model_preds_path_best).sort_values(by=['image'])\n",
            "            model_preds_last = pd.read_csv(model_preds_path_last).sort_values(by=['image'])\n",
            "\n",
            "            model_preds_best_votation = model_preds_best[['0','1','2']].copy() \n",
            "            model_preds_last_votation = model_preds_last[['0','1','2']].copy()\n",
            "\n",
            "            images_id = model_preds_best[['image']]\n",
            "            model_preds_best_votation['0'] = (model_preds_best['0'] == model_preds_best[['0','1','2']].max(axis=1)).astype(int)\n",
            "            model_preds_best_votation['1'] = (model_preds_best['1'] == model_preds_best[['0','1','2']].max(axis=1)).astype(int)\n",
            "            model_preds_best_votation['2'] = (model_preds_best['2'] == model_preds_best[['0','1','2']].max(axis=1)).astype(int)\n",
            "\n",
            "            model_preds_last_votation['0'] = (model_preds_last['0'] == model_preds_last[['0','1','2']].max(axis=1)).astype(int)\n",
            "            model_preds_last_votation['1'] = (model_preds_last['1'] == model_preds_last[['0','1','2']].max(axis=1)).astype(int)\n",
            "            model_preds_last_votation['2'] = (model_preds_last['2'] == model_preds_last[['0','1','2']].max(axis=1)).astype(int)\n",
            "\n",
            "\n",
            "            # Adicionar as previsões do modelo atual ao ensemble\n",
            "            if ensemble_preds_best is None:\n",
            "                ensemble_preds_best = model_preds_best_votation\n",
            "            else:\n",
            "                ensemble_preds_best += model_preds_best_votation\n",
            "\n",
            "            if ensemble_preds_last is None:\n",
            "                ensemble_preds_last = model_preds_last_votation\n",
            "            else:\n",
            "                ensemble_preds_last += model_preds_last_votation\n",
            "\n",
            "            num_models += 1\n",
            "\n",
            "        # Calcular a média das previsões dos modelos\n",
            "        aux = ensemble_preds_best.copy()\n",
            "        ensemble_preds_best['0'] = (aux['0'] == aux[['0','1','2']].max(axis=1)).astype(int)\n",
            "        ensemble_preds_best['1'] = (aux['1'] == aux[['0','1','2']].max(axis=1)).astype(int)\n",
            "        ensemble_preds_best['2'] = (aux['2'] == aux[['0','1','2']].max(axis=1)).astype(int)\n",
            "\n",
            "        aux = ensemble_preds_last.copy()\n",
            "        ensemble_preds_last['0'] = (aux['0'] == aux[['0','1','2']].max(axis=1)).astype(int)\n",
            "        ensemble_preds_last['1'] = (aux['1'] == aux[['0','1','2']].max(axis=1)).astype(int)\n",
            "        ensemble_preds_last['2'] = (aux['2'] == aux[['0','1','2']].max(axis=1)).astype(int)\n",
            "\n",
            "        metrics_best.update_scores(true_labels, ensemble_preds_best.to_numpy(), images_id.to_numpy())\n",
            "        metrics_last.update_scores(true_labels, ensemble_preds_last.to_numpy(), images_id.to_numpy())\n",
            "\n",
            "        metrics_best.compute_metrics()\n",
            "        metrics_last.compute_metrics()\n",
            "\n",
            "        metrics_best.save_scores()\n",
            "        metrics_last.save_scores()\n",
            "\n",
            "        for auc_metric in metrics_best.metrics_values['auc_and_roc_curve'][0]:\n",
            "            metrics_best.metrics_values[\"auc_\" + str(auc_metric)] = metrics_best.metrics_values['auc_and_roc_curve'][0][auc_metric]\n",
            "            metrics_last.metrics_values[\"auc_\" + str(auc_metric)] = metrics_last.metrics_values['auc_and_roc_curve'][0][auc_metric]\n",
            "\n",
            "        folder_name = {'folder_name': experiment_folder}\n",
            "        dict_best = {**folder_name, **metrics_best.metrics_values}\n",
            "        dict_last = {**folder_name, **metrics_last.metrics_values}\n",
            "\n",
            "        del dict_best['auc_and_roc_curve']\n",
            "        del dict_best['precision_recall_report']\n",
            "\n",
            "        del dict_last['auc_and_roc_curve']\n",
            "        del dict_last['precision_recall_report']\n",
            "\n",
            "        df_best = df_best.append(pd.DataFrame(dict_best, columns=dict_best.keys(), index=[0]), ignore_index=True)\n",
            "        df_last = df_last.append(pd.DataFrame(dict_last, columns=dict_last.keys(), index=[0]), ignore_index=True)\n",
            "\n",
            "    except Exception as e:\n",
            "        print(\"Erro no experimento \", experiment_folder)\n",
            "        print(e)\n",
            "\n",
            "\n",
            "df_best.to_csv(os.path.join(folder_path, 'ensemble_voting_best.csv'), index=False)\n",
            "df_last.to_csv(os.path.join(folder_path, 'ensemble_voting_last.csv'), index=False)\n"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Calculate metrics for each model of each experiments"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import numpy as np\n",
            "from raug.metrics_2 import Metrics, accuracy\n",
            "from raug.utils.loader import get_labels_frequency\n",
            "import pandas as pd\n",
            "\n",
            "# Especificar o caminho para a pasta \"best_results\"\n",
            "folder_path = \"best_results\"\n",
            "_csv_path_test = \"/home/a52550/Desktop/datasets/ISIC2017/test/ISIC-2017_Test_v2_Part3_GroundTruth.csv\"\n",
            "true_labels = pd.read_csv(_csv_path_test).sort_values(by=['image_id'])['category']\n",
            "\n",
            "# Inicializar as variáveis para armazenar as previsões dos modelos\n",
            "ensemble_preds_best = None\n",
            "ensemble_preds_last = None\n",
            "num_models = 0\n",
            "ser_lab_freq = get_labels_frequency(_csv_path_test, \"category\", \"image_id\")\n",
            "_labels_name = ser_lab_freq.index.values #np.reshape(ser_lab_freq.index.values, (ser_lab_freq.index.values.shape[0], 1))\n",
            "\n",
            "# Percorrer as pastas de cada experimento\n",
            "for experiment_folder in os.listdir(folder_path):\n",
            "\n",
            "    df_best = pd.DataFrame()\n",
            "    df_last = pd.DataFrame()\n",
            "\n",
            "\n",
            "    if \".csv\" in experiment_folder or \".txt\" in experiment_folder:\n",
            "        continue\n",
            "\n",
            "    experiment_path = os.path.join(folder_path, experiment_folder)\n",
            "\n",
            "    if \"results_best.csv\" in os.listdir(experiment_path):\n",
            "        continue\n",
            "\n",
            "    print(\"Experimento: \", experiment_folder)\n",
            "\n",
            "    ensemble_preds_best = None\n",
            "    ensemble_preds_last = None\n",
            "\n",
            "    model_folders = os.listdir(experiment_path)\n",
            "\n",
            "    # Check if substring \"senet154\" is present in model_folders\n",
            "    if any(\"senet154\" in s for s in model_folders):\n",
            "        continue\n",
            "\n",
            "    \n",
            "    # Cria path para o experimento atual\n",
            "    if 'ensemble_average' in model_folders:\n",
            "        model_folders.remove('ensemble_average')\n",
            "    else:\n",
            "        os.mkdir(os.path.join(folder_path, experiment_folder, 'ensemble_average'))\n",
            "        os.mkdir(os.path.join(_metric_options_best['save_all_path']))\n",
            "        os.mkdir(os.path.join(_metric_options_last['save_all_path']))\n",
            "\n",
            "    if 'ensemble_3_best_average' in model_folders:\n",
            "        model_folders.remove('ensemble_3_best_average')\n",
            "    \n",
            "    if 'ensemble_votation' in model_folders:\n",
            "        model_folders.remove('ensemble_votation')\n",
            "\n",
            "    if 'DAandPPlatex.txt' in model_folders:\n",
            "        model_folders.remove('DAandPPlatex.txt')\n",
            "\n",
            "    model_folders = [x for x in model_folders if \".csv\" not in x]\n",
            "\n",
            "    try:\n",
            "\n",
            "        # Percorrer as pastas de cada modelo\n",
            "        for model_folder in model_folders:\n",
            "\n",
            "            model_path = os.path.join(experiment_path, model_folder)\n",
            "            _metric_options_best = {\n",
            "                'save_all_path': os.path.join(model_path, 'new_test_pred_best'),\n",
            "                'pred_name_scores': 'predictions.csv',\n",
            "            }\n",
            "            _metric_options_last = {\n",
            "                'save_all_path': os.path.join(model_path, 'new_test_pred_last'),\n",
            "                'pred_name_scores': 'predictions.csv',\n",
            "            }\n",
            "\n",
            "            if 'new_test_pred_best' in os.listdir(model_path):\n",
            "                continue\n",
            "            else:\n",
            "                os.mkdir(os.path.join(model_path, 'new_test_pred_best'))\n",
            "            if 'new_test_pred_last' in os.listdir(model_path):\n",
            "                continue\n",
            "            else:\n",
            "                os.mkdir(os.path.join(model_path, 'new_test_pred_last'))\n",
            "\n",
            "            # Carregar as previsões do modelo atual\n",
            "            model_preds_path_best = os.path.join(model_path, \"test_pred_best/predictions.csv\")\n",
            "            model_preds_path_last = os.path.join(model_path, \"test_pred_last/predictions.csv\")\n",
            "\n",
            "            model_preds_best = pd.read_csv(model_preds_path_best).sort_values(by=['image'])\n",
            "            model_preds_last = pd.read_csv(model_preds_path_last).sort_values(by=['image'])\n",
            "\n",
            "            metrics_best = Metrics ([\"accuracy\", \"topk_accuracy\", \"balanced_accuracy\", \"conf_matrix\" \"plot_conf_matrix\", \"precision_recall_report\", \"auc_and_roc_curve\", \"auc\"] , _labels_name, _metric_options_best)\n",
            "            metrics_last = Metrics ([\"accuracy\", \"topk_accuracy\", \"balanced_accuracy\", \"conf_matrix\" \"plot_conf_matrix\", \"precision_recall_report\", \"auc_and_roc_curve\", \"auc\"] , _labels_name, _metric_options_last)\n",
            "\n",
            "            metrics_best.update_scores(true_labels, model_preds_best[['0','1','2']].to_numpy(), model_preds_best[['image']].to_numpy())\n",
            "            metrics_last.update_scores(true_labels, model_preds_best[['0','1','2']].to_numpy(), model_preds_best[['image']].to_numpy())\n",
            "\n",
            "            metrics_best.compute_metrics()\n",
            "            metrics_last.compute_metrics()\n",
            "\n",
            "            metrics_best.save_scores()\n",
            "            metrics_last.save_scores()\n",
            "\n",
            "            for auc_metric in metrics_best.metrics_values['auc_and_roc_curve'][0]:\n",
            "                metrics_best.metrics_values[\"auc_\" + str(auc_metric)] = metrics_best.metrics_values['auc_and_roc_curve'][0][auc_metric]\n",
            "                metrics_last.metrics_values[\"auc_\" + str(auc_metric)] = metrics_last.metrics_values['auc_and_roc_curve'][0][auc_metric]\n",
            "            \n",
            "            # del metrics_best.metrics_values['conf_matrix']\n",
            "            del metrics_best.metrics_values['auc_and_roc_curve']\n",
            "            del metrics_best.metrics_values['precision_recall_report']\n",
            "\n",
            "            # del metrics_last.metrics_values['conf_matrix']\n",
            "            del metrics_last.metrics_values['auc_and_roc_curve']\n",
            "            del metrics_last.metrics_values['precision_recall_report']\n",
            "\n",
            "            folder_name = {'folder_name': model_folder, 'model_name': model_folder.split('_fold')[0]}\n",
            "            dict_best = {**folder_name, **metrics_best.metrics_values}\n",
            "            dict_last = {**folder_name, **metrics_last.metrics_values}\n",
            "\n",
            "\n",
            "            df_best = df_best.append(pd.DataFrame(dict_best, columns=dict_best.keys(), index=[0]), ignore_index=True)\n",
            "            df_last = df_last.append(pd.DataFrame(dict_last, columns=dict_last.keys(), index=[0]), ignore_index=True)\n",
            "\n",
            "    except Exception as e:\n",
            "        print(\"Erro no experimento \", experiment_folder)\n",
            "        print(e)\n",
            "\n",
            "\n",
            "    df_best.to_csv(os.path.join(experiment_path, 'results_best.csv'), index=False)\n",
            "    df_last.to_csv(os.path.join(experiment_path, 'results_last.csv'), index=False)\n",
            "\n",
            "# Avaliar a precisão do modelo de ensemble\n",
            "# true_classes_path = os.path.join(folder_path, \"true_classes.csv\")\n",
            "# true_classes = np.loadtxt(_csv_path_test, delimiter=\",\", skiprows=1)\n",
            "\n",
            "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
            "\n",
            "# accuracy = accuracy_score(true_classes, ensemble_classes)\n",
            "# precision = precision_score(true_classes, ensemble_classes, average=\"macro\")\n",
            "# recall = recall_score(true_classes, ensemble_classes, average=\"macro\")\n",
            "# f1 = f1_score(true_classes, ensemble_classes, average=\"macro\")\n",
            "\n",
            "# # Imprimir as métricas de avaliação\n",
            "# print(f\"Acurácia: {accuracy:.3f}\")\n",
            "# print(f\"Precisão: {precision:.3f}\")\n",
            "# print(f\"Recall: {recall:.3f}\")\n",
            "# print(f\"F1-score: {f1:.3f}\")\n"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Calculate the metrics for the best ensemble"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import numpy as np\n",
            "from raug.metrics_2 import Metrics, accuracy\n",
            "from raug.utils.loader import get_labels_frequency\n",
            "import pandas as pd\n",
            "\n",
            "# Especificar o caminho para a pasta \"best_results\"\n",
            "folder_path = \"best_results\"\n",
            "_csv_path_test = \"/home/a52550/Desktop/datasets/ISIC2017/test/ISIC-2017_Test_v2_Part3_GroundTruth.csv\"\n",
            "true_labels = pd.read_csv(_csv_path_test).sort_values(by=['image_id'])['category']\n",
            "\n",
            "# Inicializar as variáveis para armazenar as previsões dos modelos\n",
            "ensemble_preds_best = None\n",
            "ensemble_preds_last = None\n",
            "num_models = 0\n",
            "ser_lab_freq = get_labels_frequency(_csv_path_test, \"category\", \"image_id\")\n",
            "_labels_name = ser_lab_freq.index.values #np.reshape(ser_lab_freq.index.values, (ser_lab_freq.index.values.shape[0], 1))\n",
            "\n",
            "# Percorrer as pastas de cada experimento\n",
            "experiment_folder = 'DA2_dull_razor_shades_of_gray_cropped_images_folder'\n",
            "\n",
            "try:\n",
            "\n",
            "    print(\"Experimento: \", experiment_folder)\n",
            "\n",
            "    experiment_path = os.path.join(folder_path, experiment_folder)\n",
            "\n",
            "    ensemble_preds_best = None\n",
            "\n",
            "    # Carregar as previsões do modelo atual\n",
            "    model_preds_path_best = '/home/a52550/Desktop/masters/cnn/learning_cycle/benchmarks/isic/best_results/DA2_dull_razor_shades_of_gray_cropped_images_folder/ensemble_3_best_average/best/predictions.csv'\n",
            "\n",
            "    model_preds_best = pd.read_csv(model_preds_path_best).sort_values(by=['image'])\n",
            "\n",
            "    metrics_best = Metrics ([\"accuracy\", \"topk_accuracy\", \"balanced_accuracy\", \"conf_matrix\" \"plot_conf_matrix\", \"precision_recall_report\", \"auc_and_roc_curve\", \"auc\"] , _labels_name)\n",
            "\n",
            "    metrics_best.update_scores(true_labels, model_preds_best[['0','1','2']].to_numpy(), model_preds_best[['image']].to_numpy())\n",
            "\n",
            "    metrics_best.compute_metrics()\n",
            "\n",
            "    print(metrics_best.metrics_values)\n",
            "\n",
            "\n",
            "except Exception as e:\n",
            "    print(\"Erro no experimento \", experiment_folder)\n",
            "    print(e)\n",
            "\n",
            "# Avaliar a precisão do modelo de ensemble\n",
            "# true_classes_path = os.path.join(folder_path, \"true_classes.csv\")\n",
            "# true_classes = np.loadtxt(_csv_path_test, delimiter=\",\", skiprows=1)\n",
            "\n",
            "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
            "\n",
            "# accuracy = accuracy_score(true_classes, ensemble_classes)\n",
            "# precision = precision_score(true_classes, ensemble_classes, average=\"macro\")\n",
            "# recall = recall_score(true_classes, ensemble_classes, average=\"macro\")\n",
            "# f1 = f1_score(true_classes, ensemble_classes, average=\"macro\")\n",
            "\n",
            "# # Imprimir as métricas de avaliação\n",
            "# print(f\"Acurácia: {accuracy:.3f}\")\n",
            "# print(f\"Precisão: {precision:.3f}\")\n",
            "# print(f\"Recall: {recall:.3f}\")\n",
            "# print(f\"F1-score: {f1:.3f}\")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import numpy as np\n",
            "from raug.metrics_2 import Metrics, accuracy\n",
            "from raug.utils.loader import get_labels_frequency\n",
            "import pandas as pd\n",
            "\n",
            "# Especificar o caminho para a pasta \"best_results\"\n",
            "folder_path = \"best_results\"\n",
            "_csv_path_test = \"/home/a52550/Desktop/datasets/ISIC2017/test/ISIC-2017_Test_v2_Part3_GroundTruth.csv\"\n",
            "true_labels = pd.read_csv(_csv_path_test).sort_values(by=['image_id'])['category']\n",
            "\n",
            "# Inicializar as variáveis para armazenar as previsões dos modelos\n",
            "ensemble_preds_best = None\n",
            "ensemble_preds_last = None\n",
            "num_models = 0\n",
            "ser_lab_freq = get_labels_frequency(_csv_path_test, \"category\", \"image_id\")\n",
            "_labels_name = ser_lab_freq.index.values #np.reshape(ser_lab_freq.index.values, (ser_lab_freq.index.values.shape[0], 1))\n",
            "\n",
            "df_best = pd.DataFrame()\n",
            "df_last = pd.DataFrame()\n",
            "\n",
            "experiment_folder = 'DA2_dull_razor_shades_of_gray_cropped_images_folder'\n",
            "\n",
            "print(\"Experimento: \", experiment_folder)\n",
            "\n",
            "\n",
            "experiment_path = os.path.join(folder_path, experiment_folder)\n",
            "\n",
            "ensemble_preds_best = None\n",
            "ensemble_preds_last = None\n",
            "\n",
            "model_folders = os.listdir(experiment_path)\n",
            "\n",
            "\n",
            "# Cria path para o experimento atual\n",
            "if 'ensemble_average' in model_folders:\n",
            "    model_folders.remove('ensemble_average')\n",
            "\n",
            "if 'ensemble_3_best_average' in model_folders:\n",
            "    model_folders.remove('ensemble_3_best_average')\n",
            "\n",
            "if 'ensemble_votation' in model_folders:\n",
            "    model_folders.remove('ensemble_votation')\n",
            "\n",
            "if 'DAandPPlatex.txt' in model_folders:\n",
            "    model_folders.remove('DAandPPlatex.txt')\n",
            "\n",
            "model_folders = [x for x in model_folders if \".csv\" not in x]\n",
            "\n",
            "try:\n",
            "\n",
            "    all_preds_best = None\n",
            "    all_preds_last = None\n",
            "\n",
            "    # Percorrer as pastas de cada modelo\n",
            "    for model_folder in model_folders:\n",
            "\n",
            "        model_path = os.path.join(experiment_path, model_folder)\n",
            "\n",
            "        # Carregar as previsões do modelo atual\n",
            "        model_preds_path_best = os.path.join(model_path, \"test_pred_best/predictions.csv\")\n",
            "        model_preds_path_last = os.path.join(model_path, \"test_pred_last/predictions.csv\")\n",
            "\n",
            "        # Merge das previsões do modelo atual com as previsões de todos os modelos\n",
            "        if all_preds_best is None:\n",
            "            model_preds_best = pd.read_csv(model_preds_path_best).sort_values(by=['image'])[['image', 'REAL', 'PRED']]\n",
            "            model_preds_last = pd.read_csv(model_preds_path_last).sort_values(by=['image'])[['image', 'REAL', 'PRED']]\n",
            "\n",
            "            #Substituir nome da coluna PRED por nome do modelo\n",
            "            model_preds_best.rename(columns={'PRED': model_folder.split('_fold')[0]}, inplace=True)\n",
            "            model_preds_last.rename(columns={'PRED': model_folder.split('_fold')[0]}, inplace=True)\n",
            "\n",
            "            all_preds_best = model_preds_best\n",
            "            all_preds_last = model_preds_last\n",
            "        else:\n",
            "            model_preds_best = pd.read_csv(model_preds_path_best).sort_values(by=['image'])[['image', 'PRED']]\n",
            "            model_preds_last = pd.read_csv(model_preds_path_last).sort_values(by=['image'])[['image', 'PRED']]\n",
            "\n",
            "            #Substituir nome da coluna PRED por nome do modelo\n",
            "            model_preds_best.rename(columns={'PRED': model_folder.split('_fold')[0]}, inplace=True)\n",
            "            model_preds_last.rename(columns={'PRED': model_folder.split('_fold')[0]}, inplace=True)\n",
            "\n",
            "            all_preds_best = pd.merge(all_preds_best, model_preds_best, on='image')\n",
            "            all_preds_last = pd.merge(all_preds_last, model_preds_last, on='image')\n",
            "\n",
            "\n",
            "except Exception as e:\n",
            "    print(\"Erro no experimento \", experiment_folder)\n",
            "    print(e)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "# Define a function to count correct guesses for each row\n",
            "def count_correct_guesses(row):\n",
            "    correct_guesses = 0\n",
            "    for model in all_preds_best.columns[2:-1]:\n",
            "        if (row[model] == row['REAL']):\n",
            "            correct_guesses += 1\n",
            "    return correct_guesses\n",
            "\n",
            "# Create a new column to store the count of correct guesses\n",
            "all_preds_best['correct_guesses'] = all_preds_best.apply(count_correct_guesses, axis=1)\n",
            "\n",
            "all_preds_best.to_csv('count_correct_guesses.csv', index=False)\n",
            "\n",
            "# Def"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Create results_all_models_all_experiments_new"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import numpy as np\n",
            "from raug.metrics_2 import Metrics, accuracy\n",
            "from raug.utils.loader import get_labels_frequency\n",
            "import pandas as pd\n",
            "from raug.utils import classification_metrics as cmet\n",
            "\n",
            "# Especificar o caminho para a pasta \"best_results\"\n",
            "folder_path = \"best_results\"\n",
            "\n",
            "df = None\n",
            "\n",
            "# Percorrer as pastas de cada experimento\n",
            "for experiment_folder in os.listdir(folder_path):\n",
            "\n",
            "    try:\n",
            "        if \".csv\" in experiment_folder or \".txt\" in experiment_folder:\n",
            "            continue\n",
            "\n",
            "        experiment_path = os.path.join(folder_path, experiment_folder)\n",
            "\n",
            "        ensemble_preds_best = None\n",
            "\n",
            "        # Check if substring \"senet154\" is present in model_folders\n",
            "        if any(\"senet154\" in s for s in os.listdir(experiment_path)):\n",
            "            print(\"Experimento \", experiment_folder, \" não será avaliado\")\n",
            "            continue\n",
            "\n",
            "        print(\"Experimento: \", experiment_folder)\n",
            "\n",
            "\n",
            "        # Carregar as previsões do modelo atual\n",
            "        results_path_csv = os.path.join(experiment_path, \"results_best.csv\")\n",
            "\n",
            "        results = pd.read_csv(results_path_csv)[['model_name','balanced_accuracy']].sort_values(by=['model_name'])\n",
            "        \n",
            "        #rename columns to experiment name\n",
            "        results.rename(columns={'balanced_accuracy': experiment_folder}, inplace=True)\n",
            "\n",
            "        if df is None:\n",
            "            df = results\n",
            "        else:\n",
            "            #merge by model_name\n",
            "            df = pd.merge(df, results, on='model_name', how='left')\n",
            "\n",
            "\n",
            "    except Exception as e:\n",
            "        print('Error: ', e)\n",
            "        continue\n",
            "\n",
            "df.to_csv(os.path.join(folder_path, 'results_all_models_all_experiments_new.csv'), index=False)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# from pydrive.auth import GoogleAuth\n",
            "# from pydrive.drive import GoogleDrive\n",
            "# gauth = GoogleAuth()   \n",
            "# gauth.LocalWebserverAuth()\n",
            "# drive = GoogleDrive(gauth)  \n",
            "\n",
            "# densenet121_fold-1_lrinit-0.0001_batchsize-32_optimizer-Adam_maxepochs-150_DA-2_PPen-None_PPha-None_PPco-shades_of_gray_PPde-None_PPno-True_PPcr-cropped_images_folder_PPre-True_drop-0.0_trainjustclassifier-False_1681078943104982"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Plot graphs"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Experimento:  DA2_dull_razor_shades_of_gray_cropped_images_folder\n"
               ]
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "import os\n",
            "import pandas as pd\n",
            "\n",
            "# Especificar o caminho para a pasta \"best_results\"\n",
            "folder_path = \"best_results\"\n",
            "\n",
            "df = None\n",
            "\n",
            "experiment_folder = 'DA2_dull_razor_shades_of_gray_cropped_images_folder'\n",
            "# experiment_folder = 'DA2_CLAHE_cropped_images_folder'\n",
            "\n",
            "\n",
            "experiment_path = os.path.join(folder_path, experiment_folder)\n",
            "\n",
            "ensemble_preds_best = None\n",
            "\n",
            "print(\"Experimento: \", experiment_folder)\n",
            "\n",
            "\n",
            "# Carregar as previsões do modelo atual\n",
            "results_path_csv = os.path.join(experiment_path, \"results_best.csv\")\n",
            "\n",
            "results = pd.read_csv(results_path_csv)[['model_name','balanced_accuracy']].sort_values(by=['model_name'])\n",
            "\n",
            "# get balanced accuracy for model_name\n",
            "all_results = results.loc[results.model_name.isin(['efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'tf_efficientnet_b5', 'tf_efficientnet_b6', 'resnest101e', 'seresnext101_32x8d', 'densenet121', 'resnext101_32x8d', 'vgg19', 'pnasnet5large' ]),:].set_index('model_name').to_dict()\n",
            "# all_results = results.loc[results.model_name.isin(['efficientnet_b2', 'tf_efficientnet_b5', 'resnest101e']),:].set_index('model_name').to_dict()\n",
            "# all_results = results.set_index('model_name').to_dict()\n",
            "\n",
            "\n",
            "ensemble_results_path_csv = os.path.join(folder_path, \"ensemble_average_best.csv\")\n",
            "ensemble_result = pd.read_csv(ensemble_results_path_csv)[['folder_name','balanced_accuracy']]\n",
            "ensemble_result = ensemble_result.loc[ensemble_result.folder_name.isin([experiment_folder]),:].set_index('folder_name').to_dict()\n",
            "\n",
            "all_results = {**all_results['balanced_accuracy'], **ensemble_result['balanced_accuracy']}\n",
            "\n",
            "#tf_efficientnet_b5, pnasnet5large, tf_efficientnet_b6, efficientnet_b4, efficientnet_b3, efficientnet_b1, resnest101e, efficientnet_b2, efficientnet_b0, seresnext101_32x8d, densenet121, vgg19, resnext101_32x8d\n",
            "\n",
            "\n",
            "# all_results['EfficientNet-B0'] = all_results.pop('efficientnet_b0')\n",
            "# all_results['EfficientNet-B1'] = all_results.pop('efficientnet_b1')\n",
            "all_results['EfficientNet-B2'] = all_results.pop('efficientnet_b2')\n",
            "# all_results['EfficientNet-B3'] = all_results.pop('efficientnet_b3')\n",
            "# all_results['EfficientNet-B4'] = all_results.pop('efficientnet_b4')\n",
            "all_results['EfficientNet-B5'] = all_results.pop('tf_efficientnet_b5')\n",
            "# all_results['EfficientNet-B6'] = all_results.pop('tf_efficientnet_b6')\n",
            "all_results['ResNest101'] = all_results.pop('resnest101e')\n",
            "# all_results['SeResNext101'] = all_results.pop('seresnext101_32x8d')\n",
            "# all_results['VGG19'] = all_results.pop('vgg19')\n",
            "# all_results['DenseNet121'] = all_results.pop('densenet121')\n",
            "# all_results['ResNext101'] = all_results.pop('resnext101_32x8d')\n",
            "# all_results['PNASNet5Large'] = all_results.pop('pnasnet5large')\n",
            "all_results['Ensemble'] = all_results.pop(experiment_folder)\n",
            "\n",
            "\n",
            "# create horizonal bar plot\n",
            "import matplotlib.pyplot as plt\n",
            "import numpy as np\n",
            "\n",
            "# Data\n",
            "r = all_results\n",
            "bars = tuple(r.keys())\n",
            "y_pos = np.arange(len(bars))\n",
            "height = list(r.values())\n",
            "\n",
            "# Create bars\n",
            "plt.barh(y_pos, height)\n",
            "\n",
            "# Create names on the x-axis\n",
            "plt.yticks(y_pos, bars)\n",
            "\n",
            "# Add title and axis names\n",
            "plt.xlabel('Balanced Accuracy')\n",
            "plt.ylabel('Model')\n",
            "\n",
            "# Color the highest bar\n",
            "plt.gca().patches[height.index(max(height))].set_facecolor('red')\n",
            "\n",
            "# Add the labels to each bar\n",
            "for i, v in enumerate(height):\n",
            "    # Round v with 4 decimals\n",
            "    v = round(v,4)\n",
            "    plt.text(v+.01, i - 0.1, str(v), fontweight='bold')\n",
            "\n",
            "# Make the right margin wider so that the labels are inside the figure\n",
            "plt.margins(0.2, 0)\n",
            "\n",
            "# Make bars thinner\n",
            "plt.gca().xaxis.set_tick_params(width=0.2)\n",
            "\n",
            "\n",
            "# Show graphic\n",
            "plt.show()\n",
            "\n",
            "# df.to_csv(os.path.join(folder_path, 'results_all_models_all_experiments_new.csv'), index=False)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# create horizonal bar plot\n",
            "import matplotlib.pyplot as plt\n",
            "import numpy as np\n",
            "\n",
            "#Balanced accuracy for each model - no pre-processing and no data augmentation\n",
            "data = {\n",
            "    \"EfficientNet-B0\": 0.7073,\n",
            "    \"EfficientNet-B1\": 0.6654,\n",
            "    \"EfficientNet-B2\": 0.6993,\n",
            "    \"EfficientNet-B3\": 0.6767,\n",
            "    \"EfficientNet-B4\": 0.7216,\n",
            "    \"EfficientNet-B5\": 0.6976,\n",
            "    \"EfficientNet-B6\": 0.6874,\n",
            "    \"ResNest101\": 0.7344,\n",
            "    \"SeResNext101\": 0.7310,\n",
            "    \"VGG19\": 0.6922,\n",
            "    \"DenseNet121\": 0.6753,\n",
            "    \"ResNext101\": 0.6828,\n",
            "    \"PnasNet5\": 0.7406\n",
            "}\n",
            "\n",
            "# Sort the data\n",
            "data = dict(sorted(data.items(), key=lambda item: item[1]))\n",
            "\n",
            "# Data\n",
            "r = data\n",
            "bars = tuple(r.keys())\n",
            "y_pos = np.arange(len(bars))\n",
            "height = list(r.values())\n",
            "\n",
            "# Create bars\n",
            "plt.barh(y_pos, height)\n",
            "\n",
            "# Create names on the x-axis\n",
            "plt.yticks(y_pos, bars)\n",
            "\n",
            "# Add title and axis names\n",
            "plt.xlabel('Balanced Accuracy')\n",
            "plt.ylabel('Model')\n",
            "\n",
            "for h in height:\n",
            "    if h > 0.7:\n",
            "        plt.gca().patches[height.index(h)].set_facecolor('yellow')\n",
            "    else:\n",
            "        plt.gca().patches[height.index(h)].set_facecolor('red')\n",
            "# Color the highest bar\n",
            "plt.gca().patches[height.index(max(height))].set_facecolor('green')\n",
            "# Color the highest bar\n",
            "\n",
            "# Add the labels to each bar\n",
            "for i, v in enumerate(height):\n",
            "    # Round v with 4 decimals\n",
            "    v = round(v,4)\n",
            "    plt.text(v+.01, i - 0.1, str(v), fontweight='bold')\n",
            "\n",
            "# Make the right margin wider so that the labels are inside the figure\n",
            "plt.margins(0.2, 0)\n",
            "\n",
            "# Make bars thinner\n",
            "plt.gca().xaxis.set_tick_params(width=0.2)\n",
            "\n",
            "\n",
            "# Show graphic\n",
            "plt.show()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "#Balanced accuracy for each model - no pre-processing and data augmentation\n",
            "data = {\n",
            "    \"EfficientNet-B0\": 0.7170,\n",
            "    \"EfficientNet-B1\": 0.7064,\n",
            "    \"EfficientNet-B2\": 0.7006,\n",
            "    \"EfficientNet-B3\": 0.7356,\n",
            "    \"EfficientNet-B4\": 0.7441,\n",
            "    \"EfficientNet-B5\": 0.7653,\n",
            "    \"EfficientNet-B6\": 0.7651,\n",
            "    \"ResNest101\": 0.7459,\n",
            "    \"SeResNext101\": 0.7432,\n",
            "    \"DenseNet121\": 0.7182,\n",
            "    \"ResNext101\": 0.7016,\n",
            "    \"VGG19\": 0.6786,\n",
            "    \"PnasNet5\": 0.7412\n",
            "}\n",
            "\n",
            "# Sort the data\n",
            "data = dict(sorted(data.items(), key=lambda item: item[1]))\n",
            "\n",
            "# Data\n",
            "r = data\n",
            "bars = tuple(r.keys())\n",
            "y_pos = np.arange(len(bars))\n",
            "height = list(r.values())\n",
            "\n",
            "# Create bars\n",
            "plt.barh(y_pos, height)\n",
            "\n",
            "# Create names on the x-axis\n",
            "plt.yticks(y_pos, bars)\n",
            "\n",
            "# Add title and axis names\n",
            "plt.xlabel('Balanced Accuracy')\n",
            "plt.ylabel('Model')\n",
            "\n",
            "# Color the highest bar\n",
            "plt.gca().patches[height.index(max(height))].set_facecolor('red')\n",
            "\n",
            "# Add the labels to each bar\n",
            "for i, v in enumerate(height):\n",
            "    # Round v with 4 decimals\n",
            "    v = round(v,4)\n",
            "    plt.text(v+.01, i - 0.1, str(v), fontweight='bold')\n",
            "\n",
            "# Make the right margin wider so that the labels are inside the figure\n",
            "plt.margins(0.2, 0)\n",
            "\n",
            "# Make bars thinner\n",
            "plt.gca().xaxis.set_tick_params(width=0.2)\n",
            "\n",
            "\n",
            "# Show graphic\n",
            "plt.show()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "data = {\n",
            "    \"Average\": {\"With DA and PP*\": 0.8064,\"With DA\": 0.7811, \"With PP*\": 0.7758, \"Without DA and PP\": 0.7547},\n",
            "    \"Average of 3\": {\"With DA and PP*\": 0.8132,\"With DA\": 0.7939, \"With PP*\":0.7879, \"Without DA and PP\": 0.7671},\n",
            "    \"Voting\": {\"With DA and PP*\": 0.7987,\"With DA\": 0.7882, \"With PP*\": 0.7718, \"Without DA and PP\": 0.7371},\n",
            "}\n",
            "\n",
            "# Preparação dos dados para plotagem\n",
            "labels = list(data.keys())\n",
            "da_pp_values = [data[label]['With DA and PP*'] for label in labels]\n",
            "da_values = [data[label]['With DA'] for label in labels]\n",
            "pp_values = [data[label]['With PP*'] for label in labels]\n",
            "no_pp_values = [data[label]['Without DA and PP'] for label in labels]\n",
            "\n",
            "\n",
            "y = np.arange(len(labels))  # Posições dos grupos de barras\n",
            "width = 0.2  # Largura das barras\n",
            "\n",
            "# Plotagem dos resultados\n",
            "fig, ax = plt.subplots(figsize=(10, 6))\n",
            "rects1 = ax.barh(y + 3*width/2, da_pp_values, width, label='With DA and PP*')\n",
            "rects2 = ax.barh(y + width/2, da_values, width, label='With DA')\n",
            "rects3 = ax.barh(y - width/2, pp_values, width, label='With PP*')\n",
            "rects4 = ax.barh(y - 3*width/2, no_pp_values, width, label='Without DA and PP')\n",
            "\n",
            "# Adicionar rótulos, títulos e legendas\n",
            "ax.set_ylabel('Ensemble')\n",
            "ax.set_xlabel('Balanced Accuracy')\n",
            "ax.set_title('Ensemble results for each experiment')\n",
            "ax.set_yticks(y)\n",
            "ax.set_yticklabels(labels)\n",
            "ax.legend()\n",
            "\n",
            "# Adicionar rótulos em cada barra\n",
            "def autolabel(rects):\n",
            "    for rect in rects:\n",
            "        width = rect.get_width()\n",
            "        ax.annotate('{}'.format(round(width,4)),\n",
            "                    xy=(width, rect.get_y() + rect.get_height() / 2),\n",
            "                    xytext=(3, 0),  # Deslocamento horizontal e vertical\n",
            "                    textcoords=\"offset points\",  # Interpretar 'xy' como deslocamento em pontos\n",
            "                    ha='left', va='center', fontweight='bold')\n",
            "\n",
            "autolabel(rects1)\n",
            "autolabel(rects2)\n",
            "autolabel(rects3)\n",
            "autolabel(rects4)\n",
            "\n",
            "# Make the right margin wider so that the labels are inside the figure\n",
            "plt.margins(0.40, 0)\n",
            "\n",
            "annotation_text = \"*Note: Best combination of image pre-processing techniques for each ensemble.\"\n",
            "plt.annotate(annotation_text, xy=(0.55, 0), xytext=(0, -40),\n",
            "             xycoords='axes fraction', textcoords='offset points',\n",
            "             ha='right', va='top')\n",
            "\n",
            "# Make bars thinner\n",
            "plt.gca().xaxis.set_tick_params(width=0.2)\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# data = {\n",
            "#     \"EfficientNet-B0\": {\"Without PP\": 0.7073,\"A\": 0.6871,\"B\": 0.6529,\"C\": 0.6960,\"D\": 0.6623,\"BC\": 0.6968,\"ABC\": 0.6304,\"BCD\": 0.6645,\"ABCD\": 0.6096},\n",
            "#     \"EfficientNet-B1\": {\"Without PP\": 0.6654,\"A\": 0.6716,\"B\": 0.6840,\"C\": 0.6601,\"D\": 0.6880,\"BC\": 0.7016,\"ABC\": 0.6440,\"BCD\": 0.6255,\"ABCD\": 0.6944},\n",
            "#     \"EfficientNet-B2\": {\"Without PP\": 0.6993,\"A\": 0.6957,\"B\": 0.6445,\"C\": 0.7091,\"D\": 0.6572,\"BC\": 0.6833,\"ABC\": 0.6600,\"BCD\": 0.6928,\"ABCD\": 0.6262},\n",
            "#     \"EfficientNet-B3\": {\"Without PP\": 0.6767,\"A\": 0.7120,\"B\": 0.6982,\"C\": 0.7248,\"D\": 0.6830,\"BC\": 0.7010,\"ABC\": 0.6612,\"BCD\": 0.7278,\"ABCD\": 0.7260},\n",
            "#     \"EfficientNet-B4\": {\"Without PP\": 0.7216,\"A\": 0.6944,\"B\": 0.7039,\"C\": 0.7093,\"D\": 0.6734,\"BC\": 0.7317,\"ABC\": 0.6493,\"BCD\": 0.7284,\"ABCD\": 0.6470},\n",
            "#     \"EfficientNet-B5\": {\"Without PP\": 0.6976,\"A\": 0.7113,\"B\": 0.6522,\"C\": 0.7099,\"D\": 0.7250,\"BC\": 0.6816,\"ABC\": 0.6814,\"BCD\": 0.6846,\"ABCD\": 0.6958},\n",
            "#     \"EfficientNet-B6\": {\"Without PP\": 0.6874,\"A\": 0.6943,\"B\": 0.7395,\"C\": 0.7213,\"D\": 0.6735,\"BC\": 0.7139,\"ABC\": 0.7057,\"BCD\": 0.6953,\"ABCD\": 0.6856},\n",
            "#     \"ResNest101\": {\"Without PP\": 0.7344,\"A\": 0.7104,\"B\": 0.7620,\"C\": 0.7447,\"D\": 0.6993,\"BC\": 0.7083,\"ABC\": 0.6706,\"BCD\": 0.7070,\"ABCD\": 0.7306},\n",
            "#     \"SeResNext101\": {\"Without PP\": 0.7310,\"A\": 0.7032,\"B\": 0.7481,\"C\": 0.6863,\"D\": 0.7117,\"BC\": 0.7165,\"ABC\": 0.6650,\"BCD\": 0.6939,\"ABCD\": 0.6634},\n",
            "#     \"VGG19\": {\"Without PP\": 0.6922,\"A\": 0.6011,\"B\": 0.6450,\"C\": 0.6606,\"D\": 0.6121,\"BC\": 0.6506,\"ABC\": 0.6546,\"BCD\": 0.6142,\"ABCD\": 0.6532},\n",
            "#     \"DenseNet121\": {\"Without PP\": 0.6753,\"A\": 0.6716,\"B\": 0.6923,\"C\": 0.7176,\"D\": 0.6974,\"BC\": 0.6282,\"ABC\": 0.6092,\"BCD\": 0.6534,\"ABCD\": 0.6330},\n",
            "#     \"ResNext101\": {\"Without PP\": 0.6828,\"A\": 0.6731,\"B\": 0.7281,\"C\": 0.6957,\"D\": 0.7194,\"BC\": 0.7253,\"ABC\": 0.6535,\"BCD\": 0.6967,\"ABCD\": 0.6950},\n",
            "#     \"PnasNet5\": {\"Without PP\": 0.7406,\"A\": 0.6718,\"B\": 0.7271,\"C\": 0.7398,\"D\": 0.7522,\"BC\": 0.7123,\"ABC\": 0.6963,\"BCD\": 0.6871,\"ABCD\": 0.6783}\n",
            "# }\n",
            "\n",
            "data = {\n",
            "    \"PnasNet5\": {\"No DA\": 0.7406,\"DA\": 0.7412},\n",
            "    \"VGG19\": {\"No DA\": 0.6922,\"DA\": 0.6786},\n",
            "    \"ResNext101\": {\"No DA\": 0.6828,\"DA\": 0.7016},\n",
            "    \"DenseNet121\": {\"No DA\": 0.6753,\"DA\": 0.7182},\n",
            "    \"SeResNext101\": {\"No DA\": 0.7310,\"DA\": 0.7432},\n",
            "    \"ResNest101\": {\"No DA\": 0.7344,\"DA\": 0.7459},\n",
            "    \"EfficientNet-B6\": {\"No DA\": 0.6874,\"DA\": 0.7651},\n",
            "    \"EfficientNet-B5\": {\"No DA\": 0.6976,\"DA\": 0.7653},\n",
            "    \"EfficientNet-B4\": {\"No DA\": 0.7216,\"DA\": 0.7441},\n",
            "    \"EfficientNet-B3\": {\"No DA\": 0.6767,\"DA\": 0.7356},\n",
            "    \"EfficientNet-B2\": {\"No DA\": 0.6993,\"DA\": 0.7006},\n",
            "    \"EfficientNet-B1\": {\"No DA\": 0.6654,\"DA\": 0.7064},\n",
            "    \"EfficientNet-B0\": {\"No DA\": 0.7073,\"DA\": 0.7170},\n",
            "}\n",
            "\n",
            "# data = dict(sorted(data.items(), key=lambda item: item[1].get('DA')-item[1].get('No DA')))\n",
            "\n",
            "# Preparar dados\n",
            "labels = list(data.keys())\n",
            "no_pp_values = [data[label]['No DA'] for label in labels]\n",
            "da_values = [data[label]['DA'] for label in labels]\n",
            "\n",
            "# a_values = [data[label]['A'] for label in labels]\n",
            "# b_values = [data[label]['B'] for label in labels]\n",
            "# c_values = [data[label]['C'] for label in labels]\n",
            "# d_values = [data[label]['D'] for label in labels]\n",
            "# bc_values = [data[label]['BC'] for label in labels]\n",
            "# abc_values = [data[label]['ABC'] for label in labels]\n",
            "# bcd_values = [data[label]['BCD'] for label in labels]\n",
            "# abcd_values = [data[label]['ABCD'] for label in labels]\n",
            "\n",
            "\n",
            "# Criar figura\n",
            "fig, ax = plt.subplots(figsize=(10, 10))\n",
            "\n",
            "# Criar barras\n",
            "x = np.arange(len(labels))  # Localização das barras\n",
            "width = 0.4  # Largura das barras\n",
            "\n",
            "rects1 = ax.barh(x - width / 2, no_pp_values, width, label='Without DA')\n",
            "rects2 = ax.barh(x + width / 2, da_values, width, label='With DA')\n",
            "\n",
            "# rects1 = ax.bar(x - 4 * width, no_pp_values, width, label='Without PP')\n",
            "# rects2 = ax.bar(x - 3 * width, a_values, width, label='A')\n",
            "# rects3 = ax.bar(x - 2 * width, b_values, width, label='B')\n",
            "# rects4 = ax.bar(x - width, c_values, width, label='C')\n",
            "# rects5 = ax.bar(x, d_values, width, label='D')\n",
            "# rects6 = ax.bar(x + width, bc_values, width, label='BC')\n",
            "# rects7 = ax.bar(x + 2 * width, abc_values, width, label='ABC')\n",
            "# rects8 = ax.bar(x + 3 * width, bcd_values, width, label='BCD')\n",
            "# rects9 = ax.bar(x + 4 * width, abcd_values, width, label='ABCD')\n",
            "\n",
            "\n",
            "# Adicionar rótulos em cada barra\n",
            "def autolabel(rects):\n",
            "    for rect in rects:\n",
            "        width = rect.get_width()\n",
            "        ax.annotate('{}'.format(round(width,4)),\n",
            "                    xy=(width, rect.get_y() + rect.get_height() / 2),\n",
            "                    xytext=(3, 0),  # Deslocamento horizontal e vertical\n",
            "                    textcoords=\"offset points\",  # Interpretar 'xy' como deslocamento em pontos\n",
            "                    ha='left', va='center', fontweight='bold')\n",
            "        \n",
            "# Adicionar texto nas barras\n",
            "autolabel(rects1)\n",
            "autolabel(rects2)\n",
            "# autolabel(rects3)\n",
            "# autolabel(rects4)\n",
            "# autolabel(rects5)\n",
            "# autolabel(rects6)\n",
            "# autolabel(rects7)\n",
            "# autolabel(rects8)\n",
            "# autolabel(rects9)\n",
            "\n",
            "\n",
            "# Make the right margin wider so that the labels are inside the figure\n",
            "plt.margins(0.40, 0)\n",
            "\n",
            "# Adicionar texto no eixo x\n",
            "ax.set_yticks(x)\n",
            "ax.set_yticklabels(labels)\n",
            "\n",
            "# Adicionar legenda\n",
            "ax.legend()\n",
            "\n",
            "# Mostrar figura\n",
            "plt.show()\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.7.16"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
