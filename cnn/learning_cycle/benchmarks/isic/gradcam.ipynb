{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from raug.checkpoints import load_model\n",
    "from my_model import set_model\n",
    "from PIL import Image\n",
    "from aug_isic import ImgEvalTransform\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\n",
    "        \"name\": \"resnest101e\",\n",
    "        \"path\": \"best_results/DA2_dull_razor_shades_of_gray_cropped_images_folder/resnest101e_fold-1_lrinit-0.0001_batchsize-8_optimizer-AdamW_maxepochs-150_DA-2_PPen-None_PPha-dull_razor_PPco-shades_of_gray_PPde-None_PPno-True_PPcr-cropped_images_folder_PPre-True_drop-0.0_trainjustclassifier-False_1681332137441572/best-checkpoint/best-checkpoint.pth\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"efficientnet_b2\",\n",
    "        \"path\": \"best_results/DA2_dull_razor_shades_of_gray_cropped_images_folder/efficientnet_b2_fold-1_lrinit-0.0001_batchsize-8_optimizer-Adam_maxepochs-150_DA-2_PPen-None_PPha-dull_razor_PPco-shades_of_gray_PPde-None_PPno-True_PPcr-cropped_images_folder_PPre-True_drop-0.0_trainjustclassifier-False_16813227212758167/best-checkpoint/best-checkpoint.pth\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"tf_efficientnet_b5\",\n",
    "        \"path\": \"best_results/DA2_dull_razor_shades_of_gray_cropped_images_folder/tf_efficientnet_b5_fold-1_lrinit-0.0001_batchsize-8_optimizer-AdamW_maxepochs-150_DA-2_PPen-None_PPha-dull_razor_PPco-shades_of_gray_PPde-None_PPno-True_PPcr-cropped_images_folder_PPre-True_drop-0.0_trainjustclassifier-False_16812917987950535/best-checkpoint/best-checkpoint.pth\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# imagem que nenhuma rede acertou (classe 0): ISIC_0016072\n",
    "# imagem que somente effb2 acertou (classe 1): ISIC_0013321\n",
    "# imagem que somente effb5 acertou (classe 1): ISIC_0013842\n",
    "# imagem que somente as 3 redes acertaram (classe 0): ISIC_0015447\n",
    "# imagem que todas as redes acertaram (classe 2): ISIC_0012786\n",
    "\n",
    "lesion_images = [\n",
    "    {\n",
    "        \"img_id\": \"ISIC_0014434\",\n",
    "        \"class\": 0,\n",
    "        \"guess\": \"all_guessed_wrong\"\n",
    "    },\n",
    "    {\n",
    "        \"img_id\": \"ISIC_0013321\",\n",
    "        \"class\": 1,\n",
    "        \"guess\": \"only_effb2_guessed_right\"\n",
    "    },\n",
    "    {\n",
    "        \"img_id\": \"ISIC_0013842\",\n",
    "        \"class\": 1,\n",
    "        \"guess\": \"only_effb5_guessed_right\"\n",
    "    },\n",
    "    {\n",
    "        \"img_id\": \"ISIC_0015447\",\n",
    "        \"class\": 0,\n",
    "        \"guess\": \"just_the_3_guessed_right\"\n",
    "    },\n",
    "    {\n",
    "        \"img_id\": \"ISIC_0015167\",\n",
    "        \"class\": 1,\n",
    "        \"guess\": \"all_nets_guessed_right\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for lesion_image in lesion_images:\n",
    "    img_path = f\"/home/a52550/Desktop/datasets/ISIC2017/test/cropped_images/{lesion_image['img_id']}.jpg\"\n",
    "\n",
    "    i = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    if not os.path.exists(f\"gradcam/{lesion_image['guess']}\"):\n",
    "            os.makedirs(f\"gradcam/{lesion_image['guess']}\")  \n",
    "    \n",
    "    cv2.imwrite(f\"gradcam/{lesion_image['guess']}/original.png\", cv2.cvtColor(np.array(i), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    for model_configs in models:\n",
    "\n",
    "        model = set_model(model_configs['name'], num_class=3)\n",
    "\n",
    "        ckpt = torch.load(model_configs['path'],map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "        img_tensor = ImgEvalTransform(size=model.default_cfg['input_size'][1:], normalization=(model.default_cfg['mean'], model.default_cfg['std']),)(i)\n",
    "\n",
    "        if model_configs[\"name\"] == \"resnest101e\":\n",
    "            target_layers = [model.layer4[-1].conv3] # this is the last conv layer of the last block\n",
    "        elif model_configs[\"name\"] == \"efficientnet_b2\":\n",
    "            target_layers = [model.blocks[-1][-1].conv_pwl] # this is the last conv layer of the last block\n",
    "        elif model_configs[\"name\"] == \"tf_efficientnet_b5\":\n",
    "            target_layers = [model.blocks[-1][-1].conv_pwl]\n",
    "\n",
    "        cam = GradCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "        targets = [ClassifierOutputTarget(lesion_image['class'])]\n",
    "\n",
    "        grayscale_cam = cam(input_tensor=img_tensor.unsqueeze(0), targets=targets)\n",
    "\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        grayscale_cam = (grayscale_cam-np.min(grayscale_cam))/(np.max(grayscale_cam)-np.min(grayscale_cam))\n",
    "\n",
    "        img_tensor = img_tensor.permute(1, 2, 0).numpy().astype(np.float32)\n",
    "\n",
    "        img_tensor = (img_tensor-np.min(img_tensor))/(np.max(img_tensor)-np.min(img_tensor))\n",
    "\n",
    "        visualization = show_cam_on_image(img_tensor, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        cv2.imwrite(f\"gradcam/{lesion_image['guess']}/gradcam_{model_configs['name']}.png\", cv2.cvtColor(visualization, cv2.COLOR_RGB2BGR))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
